{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(r'/home/sgr/Загрузки/feat_pnt_2018_coh_vhx2.xlsx')\n",
    "df2=pd.read_csv(r'/home/sgr/Загрузки/feat_pnt_2019_coh_vhx2.csv')\n",
    "mdf=df.append(df2,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del df2\n",
    "mdf['array']=mdf['array'].apply(lambda x:np.array(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "system:index     object\n",
       "array            object\n",
       "istarget          int64\n",
       ".geo            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.stack(mdf['array'].values)\n",
    "y=mdf['istarget'].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2570 samples, validate on 643 samples\n",
      "Epoch 1/400\n",
      "2570/2570 [==============================] - 2s 925us/sample - loss: 0.6236 - accuracy: 0.6381 - val_loss: 0.5355 - val_accuracy: 0.7792\n",
      "Epoch 2/400\n",
      "2570/2570 [==============================] - 0s 131us/sample - loss: 0.5465 - accuracy: 0.6949 - val_loss: 0.5311 - val_accuracy: 0.7916\n",
      "Epoch 3/400\n",
      "2570/2570 [==============================] - 0s 122us/sample - loss: 0.5251 - accuracy: 0.7198 - val_loss: 0.4633 - val_accuracy: 0.8476\n",
      "Epoch 4/400\n",
      "2570/2570 [==============================] - 0s 125us/sample - loss: 0.5068 - accuracy: 0.7335 - val_loss: 0.4350 - val_accuracy: 0.8445\n",
      "Epoch 5/400\n",
      "2570/2570 [==============================] - 0s 130us/sample - loss: 0.5053 - accuracy: 0.7370 - val_loss: 0.4645 - val_accuracy: 0.8289\n",
      "Epoch 6/400\n",
      "2570/2570 [==============================] - 0s 116us/sample - loss: 0.4939 - accuracy: 0.7440 - val_loss: 0.5199 - val_accuracy: 0.7916\n",
      "Epoch 7/400\n",
      "2570/2570 [==============================] - 0s 114us/sample - loss: 0.4931 - accuracy: 0.7514 - val_loss: 0.4141 - val_accuracy: 0.8600\n",
      "Epoch 8/400\n",
      "2570/2570 [==============================] - 0s 114us/sample - loss: 0.4852 - accuracy: 0.7568 - val_loss: 0.4407 - val_accuracy: 0.8414\n",
      "Epoch 9/400\n",
      "2570/2570 [==============================] - 0s 114us/sample - loss: 0.4899 - accuracy: 0.7545 - val_loss: 0.4310 - val_accuracy: 0.8554\n",
      "Epoch 10/400\n",
      "2570/2570 [==============================] - 0s 115us/sample - loss: 0.4775 - accuracy: 0.7669 - val_loss: 0.4085 - val_accuracy: 0.8569\n",
      "Epoch 11/400\n",
      "2570/2570 [==============================] - 0s 115us/sample - loss: 0.4748 - accuracy: 0.7615 - val_loss: 0.4717 - val_accuracy: 0.8258\n",
      "Epoch 12/400\n",
      "2570/2570 [==============================] - 0s 114us/sample - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.3801 - val_accuracy: 0.8585\n",
      "Epoch 13/400\n",
      "2570/2570 [==============================] - 0s 113us/sample - loss: 0.4592 - accuracy: 0.7848 - val_loss: 0.5162 - val_accuracy: 0.7854\n",
      "Epoch 14/400\n",
      "2570/2570 [==============================] - 0s 116us/sample - loss: 0.4468 - accuracy: 0.7868 - val_loss: 0.3253 - val_accuracy: 0.8927\n",
      "Epoch 15/400\n",
      "2570/2570 [==============================] - 0s 114us/sample - loss: 0.4371 - accuracy: 0.7922 - val_loss: 0.4328 - val_accuracy: 0.8274\n",
      "Epoch 16/400\n",
      "2570/2570 [==============================] - 0s 114us/sample - loss: 0.4238 - accuracy: 0.7930 - val_loss: 0.3436 - val_accuracy: 0.8818\n",
      "Epoch 17/400\n",
      "2570/2570 [==============================] - 0s 115us/sample - loss: 0.4140 - accuracy: 0.8121 - val_loss: 0.3919 - val_accuracy: 0.8523\n",
      "Epoch 18/400\n",
      "2570/2570 [==============================] - 0s 114us/sample - loss: 0.4039 - accuracy: 0.8109 - val_loss: 0.3848 - val_accuracy: 0.8585\n",
      "Epoch 19/400\n",
      "2570/2570 [==============================] - 0s 130us/sample - loss: 0.3954 - accuracy: 0.8105 - val_loss: 0.4354 - val_accuracy: 0.8289\n",
      "Epoch 20/400\n",
      "2570/2570 [==============================] - 0s 121us/sample - loss: 0.3987 - accuracy: 0.8136 - val_loss: 0.4354 - val_accuracy: 0.8336\n",
      "Epoch 21/400\n",
      "2570/2570 [==============================] - 0s 115us/sample - loss: 0.3905 - accuracy: 0.8241 - val_loss: 0.4413 - val_accuracy: 0.8274\n",
      "Epoch 22/400\n",
      "2570/2570 [==============================] - 0s 116us/sample - loss: 0.3886 - accuracy: 0.8218 - val_loss: 0.4713 - val_accuracy: 0.8025\n",
      "Epoch 23/400\n",
      "2570/2570 [==============================] - 0s 115us/sample - loss: 0.3840 - accuracy: 0.8183 - val_loss: 0.4626 - val_accuracy: 0.8103\n",
      "Epoch 24/400\n",
      "2570/2570 [==============================] - 0s 119us/sample - loss: 0.3938 - accuracy: 0.8101 - val_loss: 0.3432 - val_accuracy: 0.8771\n",
      "Epoch 25/400\n",
      "2570/2570 [==============================] - 0s 114us/sample - loss: 0.3735 - accuracy: 0.8222 - val_loss: 0.3234 - val_accuracy: 0.8818\n",
      "Epoch 26/400\n",
      "2570/2570 [==============================] - 0s 115us/sample - loss: 0.3911 - accuracy: 0.8171 - val_loss: 0.4010 - val_accuracy: 0.8460\n",
      "Epoch 27/400\n",
      "2570/2570 [==============================] - 0s 113us/sample - loss: 0.3930 - accuracy: 0.8125 - val_loss: 0.4000 - val_accuracy: 0.8367\n",
      "Epoch 28/400\n",
      "2570/2570 [==============================] - 0s 114us/sample - loss: 0.3894 - accuracy: 0.8202 - val_loss: 0.5048 - val_accuracy: 0.7885\n",
      "Epoch 29/400\n",
      "2570/2570 [==============================] - 0s 115us/sample - loss: 0.3890 - accuracy: 0.8206 - val_loss: 0.3672 - val_accuracy: 0.8647\n",
      "Epoch 30/400\n",
      "2570/2570 [==============================] - 0s 115us/sample - loss: 0.3820 - accuracy: 0.8202 - val_loss: 0.5428 - val_accuracy: 0.7714\n",
      "Epoch 31/400\n",
      "2570/2570 [==============================] - 0s 115us/sample - loss: 0.3896 - accuracy: 0.8218 - val_loss: 0.6236 - val_accuracy: 0.7356\n",
      "Epoch 32/400\n",
      "2570/2570 [==============================] - 0s 128us/sample - loss: 0.3779 - accuracy: 0.8268 - val_loss: 0.3926 - val_accuracy: 0.8383\n",
      "Epoch 33/400\n",
      "2570/2570 [==============================] - 0s 130us/sample - loss: 0.3884 - accuracy: 0.8191 - val_loss: 0.3531 - val_accuracy: 0.8647\n",
      "Epoch 34/400\n",
      "2570/2570 [==============================] - 0s 130us/sample - loss: 0.3859 - accuracy: 0.8140 - val_loss: 0.5196 - val_accuracy: 0.7807\n",
      "Epoch 35/400\n",
      "2570/2570 [==============================] - 0s 131us/sample - loss: 0.3874 - accuracy: 0.8183 - val_loss: 0.4834 - val_accuracy: 0.8056\n",
      "Epoch 36/400\n",
      "2570/2570 [==============================] - 0s 135us/sample - loss: 0.3837 - accuracy: 0.8222 - val_loss: 0.5976 - val_accuracy: 0.7449\n",
      "Epoch 37/400\n",
      "2570/2570 [==============================] - 0s 128us/sample - loss: 0.3747 - accuracy: 0.8268 - val_loss: 0.4046 - val_accuracy: 0.8460\n",
      "Epoch 38/400\n",
      "2570/2570 [==============================] - 0s 131us/sample - loss: 0.3789 - accuracy: 0.8233 - val_loss: 0.5607 - val_accuracy: 0.7605\n",
      "Epoch 39/400\n",
      "2570/2570 [==============================] - 0s 128us/sample - loss: 0.3763 - accuracy: 0.8272 - val_loss: 0.5752 - val_accuracy: 0.7496\n",
      "Epoch 40/400\n",
      "2570/2570 [==============================] - 0s 123us/sample - loss: 0.3780 - accuracy: 0.8265 - val_loss: 0.4631 - val_accuracy: 0.8149\n",
      "Epoch 41/400\n",
      "2570/2570 [==============================] - 0s 144us/sample - loss: 0.3846 - accuracy: 0.8175 - val_loss: 0.6903 - val_accuracy: 0.6983\n",
      "Epoch 42/400\n",
      "2570/2570 [==============================] - 0s 133us/sample - loss: 0.3802 - accuracy: 0.8214 - val_loss: 0.3637 - val_accuracy: 0.8694\n",
      "Epoch 43/400\n",
      "2570/2570 [==============================] - 0s 134us/sample - loss: 0.3658 - accuracy: 0.8284 - val_loss: 0.4142 - val_accuracy: 0.8305\n",
      "Epoch 44/400\n",
      "2570/2570 [==============================] - 0s 132us/sample - loss: 0.3739 - accuracy: 0.8265 - val_loss: 0.4583 - val_accuracy: 0.8212\n",
      "Epoch 45/400\n",
      "2570/2570 [==============================] - 0s 147us/sample - loss: 0.3730 - accuracy: 0.8249 - val_loss: 0.4088 - val_accuracy: 0.8445\n",
      "Epoch 46/400\n",
      "2570/2570 [==============================] - 0s 147us/sample - loss: 0.3733 - accuracy: 0.8218 - val_loss: 0.5159 - val_accuracy: 0.7869\n",
      "Epoch 47/400\n",
      "2570/2570 [==============================] - 0s 138us/sample - loss: 0.3772 - accuracy: 0.8187 - val_loss: 0.6473 - val_accuracy: 0.7216\n",
      "Epoch 48/400\n",
      "2570/2570 [==============================] - 0s 135us/sample - loss: 0.3712 - accuracy: 0.8245 - val_loss: 0.4624 - val_accuracy: 0.8149\n",
      "Epoch 49/400\n",
      "2570/2570 [==============================] - 0s 135us/sample - loss: 0.3822 - accuracy: 0.8276 - val_loss: 0.6304 - val_accuracy: 0.7294\n",
      "Epoch 50/400\n",
      "2570/2570 [==============================] - 0s 134us/sample - loss: 0.3800 - accuracy: 0.8206 - val_loss: 0.4362 - val_accuracy: 0.8227\n",
      "Epoch 51/400\n",
      "2570/2570 [==============================] - 0s 163us/sample - loss: 0.3884 - accuracy: 0.8257 - val_loss: 0.3280 - val_accuracy: 0.8787\n",
      "Epoch 52/400\n",
      "2570/2570 [==============================] - 0s 170us/sample - loss: 0.3774 - accuracy: 0.8342 - val_loss: 0.5266 - val_accuracy: 0.7823\n",
      "Epoch 53/400\n",
      "2570/2570 [==============================] - 0s 153us/sample - loss: 0.3751 - accuracy: 0.8191 - val_loss: 0.3294 - val_accuracy: 0.8740\n",
      "Epoch 54/400\n",
      "2570/2570 [==============================] - 0s 163us/sample - loss: 0.3797 - accuracy: 0.8276 - val_loss: 0.4363 - val_accuracy: 0.8351\n",
      "Epoch 55/400\n",
      "2570/2570 [==============================] - 0s 149us/sample - loss: 0.3727 - accuracy: 0.8327 - val_loss: 0.3768 - val_accuracy: 0.8569\n",
      "Epoch 56/400\n",
      "2570/2570 [==============================] - 0s 146us/sample - loss: 0.3731 - accuracy: 0.8311 - val_loss: 0.3945 - val_accuracy: 0.8507\n",
      "Epoch 57/400\n",
      "2570/2570 [==============================] - 0s 147us/sample - loss: 0.3858 - accuracy: 0.8226 - val_loss: 0.5489 - val_accuracy: 0.7729\n",
      "Epoch 58/400\n",
      "2570/2570 [==============================] - 0s 155us/sample - loss: 0.3805 - accuracy: 0.8222 - val_loss: 0.4378 - val_accuracy: 0.8258\n",
      "Epoch 59/400\n",
      "2570/2570 [==============================] - 0s 172us/sample - loss: 0.3782 - accuracy: 0.8233 - val_loss: 0.5485 - val_accuracy: 0.7698\n",
      "Epoch 60/400\n",
      "2570/2570 [==============================] - 0s 151us/sample - loss: 0.3717 - accuracy: 0.8284 - val_loss: 0.4491 - val_accuracy: 0.8227\n",
      "Epoch 61/400\n",
      "2570/2570 [==============================] - 0s 181us/sample - loss: 0.3742 - accuracy: 0.8241 - val_loss: 0.5205 - val_accuracy: 0.7963\n",
      "Epoch 62/400\n",
      "2570/2570 [==============================] - 0s 155us/sample - loss: 0.3762 - accuracy: 0.8304 - val_loss: 0.4464 - val_accuracy: 0.8243\n",
      "Epoch 63/400\n",
      "2570/2570 [==============================] - 0s 161us/sample - loss: 0.3802 - accuracy: 0.8198 - val_loss: 0.3743 - val_accuracy: 0.8569\n",
      "Epoch 64/400\n",
      "2570/2570 [==============================] - 0s 173us/sample - loss: 0.3703 - accuracy: 0.8288 - val_loss: 0.4669 - val_accuracy: 0.8149\n",
      "Epoch 65/400\n",
      "2570/2570 [==============================] - 0s 156us/sample - loss: 0.3721 - accuracy: 0.8300 - val_loss: 0.3525 - val_accuracy: 0.8647\n",
      "Epoch 00065: early stopping\n",
      "3213/1 - 0s - loss: 0.2180 - accuracy: 0.8422\n",
      "train_score [0.3662246292786846, 0.84220356]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input,Conv1D, Activation, GlobalMaxPooling1D, BatchNormalization, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inp=Input(shape=(16,3))\n",
    "conv=Conv1D(5, 3, use_bias=False, name='conv1')(inp)\n",
    "conv=GlobalMaxPooling1D()(conv)\n",
    "conv = BatchNormalization(momentum=0.8)(conv)\n",
    "\n",
    "conv=Dense(1,use_bias=True, activation='sigmoid')(conv)\n",
    "# conv=Dense(1,use_bias=True)(conv)\n",
    "model=Model(inputs=inp,outputs=conv)\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# filepath=r'/home/sgr/Загрузки/coh_model_simple1.h5'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', mode='min', patience=40, verbose=1)\n",
    "# mcp_save = ModelCheckpoint(filepath, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=25, verbose=1, min_delta=1e-4, mode='min')\n",
    "\n",
    "# model.fit(X, y, batch_size=16, epochs=400, verbose=1, callbacks=[earlyStopping, mcp_save,reduce_lr_loss], validation_split=0.2)\n",
    "\n",
    "model.fit(X, y, batch_size=16, epochs=400, verbose=1, callbacks=[earlyStopping,reduce_lr_loss], validation_split=0.2)\n",
    "print(\"train_score\", model.evaluate(X, y, batch_size=16, verbose=2))\n",
    "\n",
    "# model.load_weights(filepath)\n",
    "\n",
    "\n",
    "# print(\"train_score\", model.evaluate(x_train, y_train, batch_size=16, verbose=2))\n",
    "# print(\"valid_score\", model.evaluate(x_test, y_test, batch_size=16, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'/home/sgr/Загрузки/feat_pnt_2018_coh_vhx2.csv')\n",
    "df2=pd.read_csv(r'/home/sgr/Загрузки/feat_pnt_2019_coh_vhx2.csv')\n",
    "df.rename(columns={'s1_2018': 'array'}, inplace=True)\n",
    "df2.rename(columns={'s1_2019': 'array'}, inplace=True)\n",
    "mdf=df.append(df2,ignore_index=True)\n",
    "del df\n",
    "del df2\n",
    "mdf['array']=mdf['array'].apply(lambda x:np.array(eval(x)))\n",
    "X=np.stack(mdf['array'].values)\n",
    "y=mdf['istarget'].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3658 samples, validate on 915 samples\n",
      "Epoch 1/400\n",
      "3658/3658 [==============================] - 2s 437us/sample - loss: 19.8373 - accuracy: 0.3239 - val_loss: 31.2829 - val_accuracy: 0.0197\n",
      "Epoch 2/400\n",
      "3658/3658 [==============================] - 1s 180us/sample - loss: 19.0674 - accuracy: 0.3327 - val_loss: 31.5745 - val_accuracy: 0.0120\n",
      "Epoch 3/400\n",
      "3658/3658 [==============================] - 1s 190us/sample - loss: 17.9628 - accuracy: 0.3428 - val_loss: 32.4144 - val_accuracy: 0.0087\n",
      "Epoch 4/400\n",
      "3658/3658 [==============================] - 1s 179us/sample - loss: 17.3256 - accuracy: 0.3565 - val_loss: 32.1124 - val_accuracy: 0.0087\n",
      "Epoch 5/400\n",
      "3658/3658 [==============================] - 1s 182us/sample - loss: 16.6997 - accuracy: 0.3603 - val_loss: 32.2702 - val_accuracy: 0.0087\n",
      "Epoch 6/400\n",
      "3658/3658 [==============================] - 1s 198us/sample - loss: 16.1934 - accuracy: 0.3595 - val_loss: 32.2063 - val_accuracy: 0.0066\n",
      "Epoch 7/400\n",
      "3658/3658 [==============================] - 1s 203us/sample - loss: 15.5614 - accuracy: 0.3647 - val_loss: 28.9844 - val_accuracy: 0.0131\n",
      "Epoch 8/400\n",
      "3658/3658 [==============================] - 1s 204us/sample - loss: 14.8819 - accuracy: 0.3726 - val_loss: 31.0365 - val_accuracy: 0.0055\n",
      "Epoch 9/400\n",
      "3658/3658 [==============================] - 1s 200us/sample - loss: 13.9685 - accuracy: 0.3734 - val_loss: 28.2021 - val_accuracy: 0.0098\n",
      "Epoch 10/400\n",
      "3658/3658 [==============================] - 1s 231us/sample - loss: 11.8498 - accuracy: 0.3783 - val_loss: 22.0108 - val_accuracy: 0.0120\n",
      "Epoch 11/400\n",
      "3658/3658 [==============================] - 1s 249us/sample - loss: 10.1181 - accuracy: 0.3764 - val_loss: 17.2234 - val_accuracy: 0.0109\n",
      "Epoch 12/400\n",
      "3658/3658 [==============================] - 1s 242us/sample - loss: 6.4526 - accuracy: 0.3950 - val_loss: 10.3148 - val_accuracy: 0.0164\n",
      "Epoch 13/400\n",
      "3658/3658 [==============================] - 1s 252us/sample - loss: 3.4917 - accuracy: 0.4139 - val_loss: 5.8856 - val_accuracy: 0.0240\n",
      "Epoch 14/400\n",
      "3658/3658 [==============================] - 1s 253us/sample - loss: 1.9757 - accuracy: 0.4418 - val_loss: 2.8265 - val_accuracy: 0.0634\n",
      "Epoch 15/400\n",
      "3658/3658 [==============================] - 1s 241us/sample - loss: 1.2969 - accuracy: 0.4677 - val_loss: 1.6971 - val_accuracy: 0.1519\n",
      "Epoch 16/400\n",
      "3658/3658 [==============================] - 1s 245us/sample - loss: 1.1326 - accuracy: 0.5060 - val_loss: 1.1988 - val_accuracy: 0.2131\n",
      "Epoch 17/400\n",
      "3658/3658 [==============================] - 1s 271us/sample - loss: 1.0227 - accuracy: 0.5457 - val_loss: 1.1802 - val_accuracy: 0.2372\n",
      "Epoch 18/400\n",
      "3658/3658 [==============================] - 1s 255us/sample - loss: 0.9933 - accuracy: 0.5730 - val_loss: 0.8539 - val_accuracy: 0.4995\n",
      "Epoch 19/400\n",
      "3658/3658 [==============================] - 1s 269us/sample - loss: 1.0168 - accuracy: 0.6156 - val_loss: 1.0453 - val_accuracy: 0.4536\n",
      "Epoch 20/400\n",
      "3658/3658 [==============================] - 1s 273us/sample - loss: 0.9434 - accuracy: 0.6411 - val_loss: 0.7600 - val_accuracy: 0.6055\n",
      "Epoch 21/400\n",
      "3658/3658 [==============================] - 1s 342us/sample - loss: 0.8830 - accuracy: 0.6564 - val_loss: 0.7997 - val_accuracy: 0.5847\n",
      "Epoch 22/400\n",
      "3658/3658 [==============================] - 1s 338us/sample - loss: 0.9423 - accuracy: 0.6777 - val_loss: 0.9739 - val_accuracy: 0.5585\n",
      "Epoch 23/400\n",
      "3658/3658 [==============================] - 1s 378us/sample - loss: 0.9275 - accuracy: 0.6796 - val_loss: 0.7995 - val_accuracy: 0.6240\n",
      "Epoch 24/400\n",
      "3658/3658 [==============================] - 1s 345us/sample - loss: 0.8785 - accuracy: 0.7001 - val_loss: 0.7599 - val_accuracy: 0.6109\n",
      "Epoch 25/400\n",
      "3658/3658 [==============================] - 2s 423us/sample - loss: 0.8875 - accuracy: 0.6949 - val_loss: 0.7470 - val_accuracy: 0.6404\n",
      "Epoch 26/400\n",
      "3658/3658 [==============================] - 1s 315us/sample - loss: 0.8646 - accuracy: 0.6911 - val_loss: 0.7782 - val_accuracy: 0.6055\n",
      "Epoch 27/400\n",
      "3658/3658 [==============================] - 1s 353us/sample - loss: 0.8420 - accuracy: 0.6993 - val_loss: 0.8807 - val_accuracy: 0.5399\n",
      "Epoch 28/400\n",
      "3658/3658 [==============================] - 1s 377us/sample - loss: 0.8730 - accuracy: 0.6996 - val_loss: 0.7754 - val_accuracy: 0.6055\n",
      "Epoch 29/400\n",
      "3658/3658 [==============================] - 1s 378us/sample - loss: 0.8392 - accuracy: 0.7138 - val_loss: 0.7567 - val_accuracy: 0.6230\n",
      "Epoch 30/400\n",
      "3658/3658 [==============================] - 3s 747us/sample - loss: 0.8347 - accuracy: 0.7026 - val_loss: 0.7282 - val_accuracy: 0.6109\n",
      "Epoch 31/400\n",
      "3658/3658 [==============================] - 4s 1ms/sample - loss: 0.8560 - accuracy: 0.6993 - val_loss: 0.6961 - val_accuracy: 0.6568\n",
      "Epoch 32/400\n",
      "3658/3658 [==============================] - 4s 1ms/sample - loss: 0.8202 - accuracy: 0.6996 - val_loss: 0.7688 - val_accuracy: 0.6175\n",
      "Epoch 33/400\n",
      "3658/3658 [==============================] - 5s 1ms/sample - loss: 0.8062 - accuracy: 0.7242 - val_loss: 0.6171 - val_accuracy: 0.7224\n",
      "Epoch 34/400\n",
      "3658/3658 [==============================] - 3s 760us/sample - loss: 0.8308 - accuracy: 0.7274 - val_loss: 0.6250 - val_accuracy: 0.7126\n",
      "Epoch 35/400\n",
      "3658/3658 [==============================] - 1s 407us/sample - loss: 0.8090 - accuracy: 0.7340 - val_loss: 0.6165 - val_accuracy: 0.7235\n",
      "Epoch 36/400\n",
      "3658/3658 [==============================] - 1s 297us/sample - loss: 0.8070 - accuracy: 0.7305 - val_loss: 0.6511 - val_accuracy: 0.6831\n",
      "Epoch 37/400\n",
      "3658/3658 [==============================] - 1s 332us/sample - loss: 0.7927 - accuracy: 0.7206 - val_loss: 0.6347 - val_accuracy: 0.6962\n",
      "Epoch 38/400\n",
      "3658/3658 [==============================] - 1s 319us/sample - loss: 0.8170 - accuracy: 0.7255 - val_loss: 0.6052 - val_accuracy: 0.7388\n",
      "Epoch 39/400\n",
      "3658/3658 [==============================] - 1s 340us/sample - loss: 0.7902 - accuracy: 0.7239 - val_loss: 0.7104 - val_accuracy: 0.6426\n",
      "Epoch 40/400\n",
      "3658/3658 [==============================] - 1s 338us/sample - loss: 0.8181 - accuracy: 0.7250 - val_loss: 0.7214 - val_accuracy: 0.6350\n",
      "Epoch 41/400\n",
      "3658/3658 [==============================] - 1s 338us/sample - loss: 0.7830 - accuracy: 0.7203 - val_loss: 0.6519 - val_accuracy: 0.7202\n",
      "Epoch 42/400\n",
      "3658/3658 [==============================] - 2s 493us/sample - loss: 0.7954 - accuracy: 0.7329 - val_loss: 0.6497 - val_accuracy: 0.7268\n",
      "Epoch 43/400\n",
      "3658/3658 [==============================] - 1s 385us/sample - loss: 0.8009 - accuracy: 0.7337 - val_loss: 0.5676 - val_accuracy: 0.7945\n",
      "Epoch 44/400\n",
      "3658/3658 [==============================] - 2s 410us/sample - loss: 0.8241 - accuracy: 0.7291 - val_loss: 0.5555 - val_accuracy: 0.8098\n",
      "Epoch 45/400\n",
      "3658/3658 [==============================] - 2s 420us/sample - loss: 0.8285 - accuracy: 0.7261 - val_loss: 0.7854 - val_accuracy: 0.6164\n",
      "Epoch 46/400\n",
      "3658/3658 [==============================] - 1s 375us/sample - loss: 0.8157 - accuracy: 0.7244 - val_loss: 0.6429 - val_accuracy: 0.7355\n",
      "Epoch 47/400\n",
      "3658/3658 [==============================] - 1s 395us/sample - loss: 0.8115 - accuracy: 0.7233 - val_loss: 0.7457 - val_accuracy: 0.7016\n",
      "Epoch 48/400\n",
      "3658/3658 [==============================] - 1s 404us/sample - loss: 0.8329 - accuracy: 0.7187 - val_loss: 0.6440 - val_accuracy: 0.7344\n",
      "Epoch 49/400\n",
      "3658/3658 [==============================] - 1s 375us/sample - loss: 0.8119 - accuracy: 0.7255 - val_loss: 1.0616 - val_accuracy: 0.5934\n",
      "Epoch 50/400\n",
      "3658/3658 [==============================] - 1s 360us/sample - loss: 0.7784 - accuracy: 0.7280 - val_loss: 0.7535 - val_accuracy: 0.5956\n",
      "Epoch 51/400\n",
      "3658/3658 [==============================] - 1s 312us/sample - loss: 0.8271 - accuracy: 0.7187 - val_loss: 0.7069 - val_accuracy: 0.7016\n",
      "Epoch 52/400\n",
      "3658/3658 [==============================] - 1s 328us/sample - loss: 0.8425 - accuracy: 0.7195 - val_loss: 0.7888 - val_accuracy: 0.6579\n",
      "Epoch 53/400\n",
      "3658/3658 [==============================] - 1s 360us/sample - loss: 0.8347 - accuracy: 0.7203 - val_loss: 0.6814 - val_accuracy: 0.7290\n",
      "Epoch 54/400\n",
      "3658/3658 [==============================] - 1s 344us/sample - loss: 0.8056 - accuracy: 0.7130 - val_loss: 1.0533 - val_accuracy: 0.6492\n",
      "Epoch 55/400\n",
      "3658/3658 [==============================] - 2s 586us/sample - loss: 0.8759 - accuracy: 0.7190 - val_loss: 0.7253 - val_accuracy: 0.6863\n",
      "Epoch 56/400\n",
      "3658/3658 [==============================] - 1s 392us/sample - loss: 0.8630 - accuracy: 0.7124 - val_loss: 0.7059 - val_accuracy: 0.7443\n",
      "Epoch 57/400\n",
      "3658/3658 [==============================] - 1s 382us/sample - loss: 0.8765 - accuracy: 0.7116 - val_loss: 0.8294 - val_accuracy: 0.7016\n",
      "Epoch 58/400\n",
      "3658/3658 [==============================] - 1s 350us/sample - loss: 0.9363 - accuracy: 0.7171 - val_loss: 1.0008 - val_accuracy: 0.6667\n",
      "Epoch 59/400\n",
      "3658/3658 [==============================] - 1s 395us/sample - loss: 0.9420 - accuracy: 0.7179 - val_loss: 0.7750 - val_accuracy: 0.7464\n",
      "Epoch 60/400\n",
      "3658/3658 [==============================] - 1s 394us/sample - loss: 0.9323 - accuracy: 0.7214 - val_loss: 1.1807 - val_accuracy: 0.6164\n",
      "Epoch 61/400\n",
      "3658/3658 [==============================] - 1s 336us/sample - loss: 0.9360 - accuracy: 0.7277 - val_loss: 0.9121 - val_accuracy: 0.6896\n",
      "Epoch 62/400\n",
      "3658/3658 [==============================] - 1s 301us/sample - loss: 0.9405 - accuracy: 0.7247 - val_loss: 0.7227 - val_accuracy: 0.6995\n",
      "Epoch 63/400\n",
      "3658/3658 [==============================] - 1s 340us/sample - loss: 0.8759 - accuracy: 0.7329 - val_loss: 0.7739 - val_accuracy: 0.7574\n",
      "Epoch 64/400\n",
      "3658/3658 [==============================] - 1s 333us/sample - loss: 0.8946 - accuracy: 0.7201 - val_loss: 1.0833 - val_accuracy: 0.6415\n",
      "Epoch 65/400\n",
      "3658/3658 [==============================] - 1s 365us/sample - loss: 0.8967 - accuracy: 0.7269 - val_loss: 0.7973 - val_accuracy: 0.7311\n",
      "Epoch 66/400\n",
      "3658/3658 [==============================] - 2s 474us/sample - loss: 0.8405 - accuracy: 0.7318 - val_loss: 0.8299 - val_accuracy: 0.6896\n",
      "Epoch 67/400\n",
      "3658/3658 [==============================] - 1s 373us/sample - loss: 0.8777 - accuracy: 0.7329 - val_loss: 0.5381 - val_accuracy: 0.8240\n",
      "Epoch 68/400\n",
      "3658/3658 [==============================] - 1s 396us/sample - loss: 0.8660 - accuracy: 0.7359 - val_loss: 0.5398 - val_accuracy: 0.8262\n",
      "Epoch 69/400\n",
      "3658/3658 [==============================] - 1s 393us/sample - loss: 0.9057 - accuracy: 0.7346 - val_loss: 0.6006 - val_accuracy: 0.8153\n",
      "Epoch 70/400\n",
      "3658/3658 [==============================] - 1s 365us/sample - loss: 0.8597 - accuracy: 0.7305 - val_loss: 0.7100 - val_accuracy: 0.7519\n",
      "Epoch 71/400\n",
      "3658/3658 [==============================] - 1s 362us/sample - loss: 0.8772 - accuracy: 0.7266 - val_loss: 1.1287 - val_accuracy: 0.6667\n",
      "Epoch 72/400\n",
      "3658/3658 [==============================] - 2s 410us/sample - loss: 0.9227 - accuracy: 0.7209 - val_loss: 1.2093 - val_accuracy: 0.6251\n",
      "Epoch 73/400\n",
      "3658/3658 [==============================] - 2s 419us/sample - loss: 0.9460 - accuracy: 0.7313 - val_loss: 1.0520 - val_accuracy: 0.7158\n",
      "Epoch 74/400\n",
      "3658/3658 [==============================] - 1s 396us/sample - loss: 0.8969 - accuracy: 0.7346 - val_loss: 0.6764 - val_accuracy: 0.7541\n",
      "Epoch 75/400\n",
      "3648/3658 [============================>.] - ETA: 0s - loss: 0.9059 - accuracy: 0.7226\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3658/3658 [==============================] - 1s 377us/sample - loss: 0.9055 - accuracy: 0.7217 - val_loss: 1.1171 - val_accuracy: 0.6383\n",
      "Epoch 76/400\n",
      "3658/3658 [==============================] - 1s 374us/sample - loss: 0.8217 - accuracy: 0.7255 - val_loss: 0.6802 - val_accuracy: 0.7486\n",
      "Epoch 77/400\n",
      "3658/3658 [==============================] - 1s 394us/sample - loss: 0.8908 - accuracy: 0.7348 - val_loss: 1.0989 - val_accuracy: 0.6557\n",
      "Epoch 78/400\n",
      "3658/3658 [==============================] - 1s 319us/sample - loss: 0.8274 - accuracy: 0.7387 - val_loss: 0.7343 - val_accuracy: 0.7607\n",
      "Epoch 79/400\n",
      "3658/3658 [==============================] - 1s 319us/sample - loss: 0.8470 - accuracy: 0.7354 - val_loss: 0.5753 - val_accuracy: 0.8240\n",
      "Epoch 80/400\n",
      "3658/3658 [==============================] - 1s 343us/sample - loss: 0.8563 - accuracy: 0.7269 - val_loss: 0.6740 - val_accuracy: 0.7563\n",
      "Epoch 81/400\n",
      "3658/3658 [==============================] - 1s 340us/sample - loss: 0.8580 - accuracy: 0.7310 - val_loss: 1.1109 - val_accuracy: 0.6426\n",
      "Epoch 82/400\n",
      "3658/3658 [==============================] - 2s 467us/sample - loss: 0.8123 - accuracy: 0.7294 - val_loss: 0.9663 - val_accuracy: 0.6590\n",
      "Epoch 83/400\n",
      "3658/3658 [==============================] - 2s 491us/sample - loss: 0.8753 - accuracy: 0.7318 - val_loss: 0.7100 - val_accuracy: 0.7148\n",
      "Epoch 84/400\n",
      "3658/3658 [==============================] - 1s 409us/sample - loss: 0.8330 - accuracy: 0.7291 - val_loss: 0.8054 - val_accuracy: 0.6907\n",
      "Epoch 85/400\n",
      "3658/3658 [==============================] - 1s 312us/sample - loss: 0.8571 - accuracy: 0.7335 - val_loss: 0.8968 - val_accuracy: 0.6514\n",
      "Epoch 86/400\n",
      "3658/3658 [==============================] - 1s 311us/sample - loss: 0.8682 - accuracy: 0.7285 - val_loss: 0.6766 - val_accuracy: 0.7541\n",
      "Epoch 87/400\n",
      "3658/3658 [==============================] - 1s 335us/sample - loss: 0.8311 - accuracy: 0.7291 - val_loss: 1.0215 - val_accuracy: 0.7071\n",
      "Epoch 88/400\n",
      "3658/3658 [==============================] - 1s 341us/sample - loss: 0.8581 - accuracy: 0.7244 - val_loss: 0.9012 - val_accuracy: 0.6448\n",
      "Epoch 89/400\n",
      "3658/3658 [==============================] - 2s 415us/sample - loss: 0.8689 - accuracy: 0.7250 - val_loss: 0.6492 - val_accuracy: 0.7792\n",
      "Epoch 90/400\n",
      "3658/3658 [==============================] - 2s 529us/sample - loss: 0.8113 - accuracy: 0.7337 - val_loss: 0.6659 - val_accuracy: 0.7628\n",
      "Epoch 91/400\n",
      "3658/3658 [==============================] - 2s 500us/sample - loss: 0.8500 - accuracy: 0.7348 - val_loss: 0.8649 - val_accuracy: 0.6940\n",
      "Epoch 92/400\n",
      "3658/3658 [==============================] - 1s 368us/sample - loss: 0.8410 - accuracy: 0.7258 - val_loss: 0.8801 - val_accuracy: 0.6754\n",
      "Epoch 93/400\n",
      "3658/3658 [==============================] - 1s 399us/sample - loss: 0.7796 - accuracy: 0.7269 - val_loss: 0.6307 - val_accuracy: 0.7978\n",
      "Epoch 94/400\n",
      "3658/3658 [==============================] - 1s 383us/sample - loss: 0.8061 - accuracy: 0.7233 - val_loss: 0.7711 - val_accuracy: 0.7607\n",
      "Epoch 95/400\n",
      "3658/3658 [==============================] - 1s 393us/sample - loss: 0.8719 - accuracy: 0.7315 - val_loss: 0.8954 - val_accuracy: 0.7388\n",
      "Epoch 96/400\n",
      "3658/3658 [==============================] - 1s 369us/sample - loss: 0.8132 - accuracy: 0.7307 - val_loss: 0.6825 - val_accuracy: 0.7497\n",
      "Epoch 97/400\n",
      "3658/3658 [==============================] - 1s 371us/sample - loss: 0.8516 - accuracy: 0.7326 - val_loss: 0.7852 - val_accuracy: 0.7060\n",
      "Epoch 98/400\n",
      "3658/3658 [==============================] - 1s 404us/sample - loss: 0.7964 - accuracy: 0.7296 - val_loss: 0.6850 - val_accuracy: 0.7464\n",
      "Epoch 99/400\n",
      "3658/3658 [==============================] - 1s 370us/sample - loss: 0.8884 - accuracy: 0.7291 - val_loss: 0.6669 - val_accuracy: 0.7617\n",
      "Epoch 100/400\n",
      "3520/3658 [===========================>..] - ETA: 0s - loss: 0.8574 - accuracy: 0.7287\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "3658/3658 [==============================] - 1s 365us/sample - loss: 0.8611 - accuracy: 0.7285 - val_loss: 0.9890 - val_accuracy: 0.6317\n",
      "Epoch 101/400\n",
      "3658/3658 [==============================] - 1s 393us/sample - loss: 0.8441 - accuracy: 0.7247 - val_loss: 0.8482 - val_accuracy: 0.7137\n",
      "Epoch 102/400\n",
      "3658/3658 [==============================] - 1s 371us/sample - loss: 0.8353 - accuracy: 0.7411 - val_loss: 0.6564 - val_accuracy: 0.7738\n",
      "Epoch 103/400\n",
      "3658/3658 [==============================] - 1s 356us/sample - loss: 0.8303 - accuracy: 0.7395 - val_loss: 0.6389 - val_accuracy: 0.7858\n",
      "Epoch 104/400\n",
      "3658/3658 [==============================] - 1s 404us/sample - loss: 0.8681 - accuracy: 0.7250 - val_loss: 0.6939 - val_accuracy: 0.7705\n",
      "Epoch 105/400\n",
      "3658/3658 [==============================] - 1s 386us/sample - loss: 0.8518 - accuracy: 0.7313 - val_loss: 0.7728 - val_accuracy: 0.7213\n",
      "Epoch 106/400\n",
      "3658/3658 [==============================] - 1s 354us/sample - loss: 0.8476 - accuracy: 0.7299 - val_loss: 0.6677 - val_accuracy: 0.7617\n",
      "Epoch 107/400\n",
      "3658/3658 [==============================] - 1s 385us/sample - loss: 0.8436 - accuracy: 0.7335 - val_loss: 0.6373 - val_accuracy: 0.7923\n",
      "Epoch 00107: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f99d1d87240>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input,Conv1D, Activation, GlobalMaxPooling1D, BatchNormalization, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate, Average\n",
    "end_models=3\n",
    "\n",
    "inp=Input(shape=(16,1))\n",
    "\n",
    "outs=[]\n",
    "for i in range(end_models):   \n",
    "    conv=Conv1D(1, 3, use_bias=False)(inp)\n",
    "    conv=GlobalMaxPooling1D()(conv)\n",
    "    conv = BatchNormalization(momentum=0.8)(conv)  \n",
    "    out=Dense(1,use_bias=True)(conv)\n",
    "    outs.append(out)\n",
    "        \n",
    "out=Average()(outs)\n",
    "model=Model(inputs=inp,outputs=out)\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam')\n",
    "\n",
    "def custom_binentr(y_true, y_pred):     \n",
    "    y_tr=tf.cast(y_true, dtype=tf.float32)         \n",
    "\n",
    "#     cf0=-2.\n",
    "#     cf1=(cf0)*(-1.)-1.   \n",
    "    \n",
    "    weight=((y_tr-3.)/2.)**2\n",
    "    eps=1e-15\n",
    "    mx=1.    \n",
    "    on=tf.math.log(tf.clip_by_value(y_pred,eps,mx))    \n",
    "    tw=tf.math.log(tf.clip_by_value((1.-y_pred),eps,mx))        \n",
    "    return (-y_tr*on-(1.-y_tr)*tw)*weight\n",
    "\n",
    "\n",
    "loss=[custom_binentr,'binary_crossentropy']\n",
    "\n",
    "\n",
    "model.compile(loss=loss[0],\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "filepath=r'/home/sgr/Загрузки/coh_model_simple1.h5'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', mode='min', patience=40, verbose=1)\n",
    "mcp_save = ModelCheckpoint(filepath, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=25, verbose=1, min_delta=1e-4, mode='min')\n",
    "\n",
    "model.fit(X, y, batch_size=16, epochs=400, verbose=1, callbacks=[earlyStopping, mcp_save,reduce_lr_loss], validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cm:  [[312  79]\n",
      " [ 62 265]]\n",
      "total assesment:  0.8036211699164345\n"
     ]
    }
   ],
   "source": [
    "df2020=pd.read_csv(r'/home/sgr/Загрузки/feat_pnt_2020_coh_vhx2.csv')\n",
    "X2020=df2020['s1_2020'].apply(lambda x:np.array(eval(x)))\n",
    "pr2020=model.predict(np.stack( list(X2020.to_numpy()), axis=0 ))\n",
    "df2020['pr']=np.clip(pr2020,0,1)\n",
    "\n",
    "pr=df2020.groupby('Name').agg(lambda x:np.mean(x))\n",
    "print('cm: ',cm(pr['istarget'], (pr['pr']+0.5).astype(int), [0,1]))\n",
    "print('total assesment: ',1-(((pr['pr']+0.5).astype(int)- pr['istarget'])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    577\n",
       " 1     79\n",
       "-1     62\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((pr['pr']+0.5).astype(int)- pr['istarget']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020=pd.read_csv(r'/home/sgr/Загрузки/feat_pnt_2020_coh_vhx2_.csv')\n",
    "X2020=df2020['array'].apply(lambda x:np.array(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X2020.to_numpy())[0][None,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_26 to have shape (16, 1) but got array with shape (16, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-5c359ebc14fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpr2020\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2020\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    572\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    575\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_26 to have shape (16, 1) but got array with shape (16, 3)"
     ]
    }
   ],
   "source": [
    "pr2020=model.predict(np.stack( list(X2020.to_numpy()), axis=0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1948, 1)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr2020.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020['pred']=pr2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1491\n",
       "1     457\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((df2020['pred']+0.5).astype(int)-df2020['istarget'])**2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7654004106776181"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1491/(1491+457)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=df2020.groupby('Name').agg(lambda x:np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>istarget</th>\n",
       "      <th>.geo</th>\n",
       "      <th>pr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hand_10</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand_101</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.347064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand_102</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand_103</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand_105</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2020_95</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.689030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2020_96</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.783858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2020_97</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.798716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2020_98</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.203170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2020_99</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.749574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>718 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          istarget  .geo        pr\n",
       "Name                              \n",
       "hand_10          0   NaN  0.122720\n",
       "hand_101         0   NaN  0.347064\n",
       "hand_102         0   NaN  0.000000\n",
       "hand_103         0   NaN  0.653276\n",
       "hand_105         0   NaN  0.563253\n",
       "...            ...   ...       ...\n",
       "p2020_95         1   NaN  0.689030\n",
       "p2020_96         1   NaN  0.783858\n",
       "p2020_97         1   NaN  0.798716\n",
       "p2020_98         0   NaN  0.203170\n",
       "p2020_99         1   NaN  0.749574\n",
       "\n",
       "[718 rows x 3 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[272, 119],\n",
       "       [ 27, 300]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm(pr['istarget'], (pr['pr']+0.5).astype(int), [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    591\n",
       "1    127\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((pr['pred']+0.5).astype(int)- pr['istarget'])**2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8231197771587744"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "591/(591+127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013330160059354834"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.signal import correlate\n",
    "\n",
    "\n",
    "\n",
    "kern=[0.1662142 ,0.04972222,0.5083684 ]\n",
    "np.max(correlate(X2020[25].ravel(),kern,mode='valid'))*(-0.6410108)+0.32739487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3658 samples, validate on 915 samples\n",
      "Epoch 1/400\n",
      "3658/3658 [==============================] - 1s 297us/sample - loss: 3.7002 - accuracy: 0.5615 - val_loss: 3.8027 - val_accuracy: 0.5049\n",
      "Epoch 2/400\n",
      "3658/3658 [==============================] - 0s 129us/sample - loss: 2.9771 - accuracy: 0.5861 - val_loss: 4.0489 - val_accuracy: 0.5115\n",
      "Epoch 3/400\n",
      "3658/3658 [==============================] - 0s 118us/sample - loss: 2.5540 - accuracy: 0.6058 - val_loss: 2.8869 - val_accuracy: 0.5628\n",
      "Epoch 4/400\n",
      "3658/3658 [==============================] - 0s 119us/sample - loss: 2.1004 - accuracy: 0.6225 - val_loss: 1.8577 - val_accuracy: 0.6710\n",
      "Epoch 5/400\n",
      "3658/3658 [==============================] - 0s 118us/sample - loss: 1.6307 - accuracy: 0.6353 - val_loss: 1.6532 - val_accuracy: 0.6557\n",
      "Epoch 6/400\n",
      "3658/3658 [==============================] - 0s 117us/sample - loss: 1.3243 - accuracy: 0.6493 - val_loss: 1.7075 - val_accuracy: 0.6055\n",
      "Epoch 7/400\n",
      "3658/3658 [==============================] - 0s 116us/sample - loss: 1.1846 - accuracy: 0.6427 - val_loss: 1.4852 - val_accuracy: 0.6164\n",
      "Epoch 8/400\n",
      "3658/3658 [==============================] - 0s 125us/sample - loss: 1.0476 - accuracy: 0.6591 - val_loss: 1.1385 - val_accuracy: 0.6568\n",
      "Epoch 9/400\n",
      "3658/3658 [==============================] - 0s 130us/sample - loss: 0.9019 - accuracy: 0.6613 - val_loss: 0.8637 - val_accuracy: 0.7191\n",
      "Epoch 10/400\n",
      "3658/3658 [==============================] - 0s 126us/sample - loss: 0.8521 - accuracy: 0.6687 - val_loss: 0.7118 - val_accuracy: 0.7268\n",
      "Epoch 11/400\n",
      "3658/3658 [==============================] - 0s 116us/sample - loss: 0.7172 - accuracy: 0.6802 - val_loss: 0.7398 - val_accuracy: 0.7104\n",
      "Epoch 12/400\n",
      "3658/3658 [==============================] - 0s 118us/sample - loss: 0.6796 - accuracy: 0.6796 - val_loss: 0.5368 - val_accuracy: 0.7825\n",
      "Epoch 13/400\n",
      "3658/3658 [==============================] - 0s 119us/sample - loss: 0.6380 - accuracy: 0.6834 - val_loss: 0.5092 - val_accuracy: 0.7989\n",
      "Epoch 14/400\n",
      "3658/3658 [==============================] - 0s 122us/sample - loss: 0.5934 - accuracy: 0.7094 - val_loss: 0.5077 - val_accuracy: 0.7945\n",
      "Epoch 15/400\n",
      "3658/3658 [==============================] - 0s 129us/sample - loss: 0.5811 - accuracy: 0.7154 - val_loss: 0.4318 - val_accuracy: 0.8568\n",
      "Epoch 16/400\n",
      "3658/3658 [==============================] - 0s 118us/sample - loss: 0.5985 - accuracy: 0.7132 - val_loss: 0.4786 - val_accuracy: 0.8361\n",
      "Epoch 17/400\n",
      "3658/3658 [==============================] - 0s 125us/sample - loss: 0.5725 - accuracy: 0.7184 - val_loss: 0.5037 - val_accuracy: 0.8273\n",
      "Epoch 18/400\n",
      "3658/3658 [==============================] - 0s 120us/sample - loss: 0.5695 - accuracy: 0.7195 - val_loss: 0.4483 - val_accuracy: 0.8732\n",
      "Epoch 19/400\n",
      "3658/3658 [==============================] - 0s 117us/sample - loss: 0.5728 - accuracy: 0.7261 - val_loss: 0.4527 - val_accuracy: 0.8721\n",
      "Epoch 20/400\n",
      "3658/3658 [==============================] - 0s 118us/sample - loss: 0.5632 - accuracy: 0.7302 - val_loss: 0.4285 - val_accuracy: 0.8743\n",
      "Epoch 21/400\n",
      "3658/3658 [==============================] - 0s 117us/sample - loss: 0.5673 - accuracy: 0.7162 - val_loss: 0.4707 - val_accuracy: 0.8404\n",
      "Epoch 22/400\n",
      "3658/3658 [==============================] - 0s 121us/sample - loss: 0.5512 - accuracy: 0.7294 - val_loss: 0.4467 - val_accuracy: 0.8557\n",
      "Epoch 23/400\n",
      "3658/3658 [==============================] - 0s 121us/sample - loss: 0.5748 - accuracy: 0.7337 - val_loss: 0.4391 - val_accuracy: 0.8754\n",
      "Epoch 24/400\n",
      "3658/3658 [==============================] - 0s 119us/sample - loss: 0.5567 - accuracy: 0.7359 - val_loss: 0.4511 - val_accuracy: 0.8568\n",
      "Epoch 25/400\n",
      "3658/3658 [==============================] - 0s 127us/sample - loss: 0.5591 - accuracy: 0.7376 - val_loss: 0.3516 - val_accuracy: 0.9311\n",
      "Epoch 26/400\n",
      "3658/3658 [==============================] - 1s 144us/sample - loss: 0.5531 - accuracy: 0.7370 - val_loss: 0.4113 - val_accuracy: 0.8678\n",
      "Epoch 27/400\n",
      "3658/3658 [==============================] - 1s 138us/sample - loss: 0.5446 - accuracy: 0.7340 - val_loss: 0.4076 - val_accuracy: 0.8820\n",
      "Epoch 28/400\n",
      "3658/3658 [==============================] - 1s 140us/sample - loss: 0.5438 - accuracy: 0.7477 - val_loss: 0.3781 - val_accuracy: 0.9202\n",
      "Epoch 29/400\n",
      "3658/3658 [==============================] - 1s 144us/sample - loss: 0.5423 - accuracy: 0.7460 - val_loss: 0.3709 - val_accuracy: 0.9060\n",
      "Epoch 30/400\n",
      "3658/3658 [==============================] - 1s 138us/sample - loss: 0.5312 - accuracy: 0.7512 - val_loss: 0.3833 - val_accuracy: 0.9093\n",
      "Epoch 31/400\n",
      "3658/3658 [==============================] - 1s 144us/sample - loss: 0.5543 - accuracy: 0.7474 - val_loss: 0.3952 - val_accuracy: 0.9016\n",
      "Epoch 32/400\n",
      "3658/3658 [==============================] - 1s 142us/sample - loss: 0.5441 - accuracy: 0.7526 - val_loss: 0.3436 - val_accuracy: 0.9301\n",
      "Epoch 33/400\n",
      "3658/3658 [==============================] - 1s 144us/sample - loss: 0.5524 - accuracy: 0.7521 - val_loss: 0.4674 - val_accuracy: 0.8678\n",
      "Epoch 34/400\n",
      "3658/3658 [==============================] - 0s 131us/sample - loss: 0.5409 - accuracy: 0.7619 - val_loss: 0.4443 - val_accuracy: 0.8798\n",
      "Epoch 35/400\n",
      "3658/3658 [==============================] - 0s 136us/sample - loss: 0.5295 - accuracy: 0.7616 - val_loss: 0.5291 - val_accuracy: 0.8383\n",
      "Epoch 36/400\n",
      "3658/3658 [==============================] - 1s 151us/sample - loss: 0.5391 - accuracy: 0.7589 - val_loss: 0.3721 - val_accuracy: 0.9104\n",
      "Epoch 37/400\n",
      "3658/3658 [==============================] - 1s 147us/sample - loss: 0.5330 - accuracy: 0.7736 - val_loss: 0.3606 - val_accuracy: 0.9180\n",
      "Epoch 38/400\n",
      "3658/3658 [==============================] - 1s 168us/sample - loss: 0.5307 - accuracy: 0.7679 - val_loss: 0.4148 - val_accuracy: 0.8929\n",
      "Epoch 39/400\n",
      "3658/3658 [==============================] - 1s 159us/sample - loss: 0.5228 - accuracy: 0.7764 - val_loss: 0.4306 - val_accuracy: 0.8885\n",
      "Epoch 40/400\n",
      "3658/3658 [==============================] - 1s 160us/sample - loss: 0.5231 - accuracy: 0.7671 - val_loss: 0.3753 - val_accuracy: 0.9137\n",
      "Epoch 41/400\n",
      "3658/3658 [==============================] - 1s 142us/sample - loss: 0.5061 - accuracy: 0.7777 - val_loss: 0.5544 - val_accuracy: 0.8393\n",
      "Epoch 42/400\n",
      "3658/3658 [==============================] - 1s 158us/sample - loss: 0.5116 - accuracy: 0.7805 - val_loss: 0.3817 - val_accuracy: 0.9049\n",
      "Epoch 43/400\n",
      "3658/3658 [==============================] - 1s 162us/sample - loss: 0.5269 - accuracy: 0.7816 - val_loss: 0.3263 - val_accuracy: 0.9366\n",
      "Epoch 44/400\n",
      "3658/3658 [==============================] - 1s 152us/sample - loss: 0.5245 - accuracy: 0.7739 - val_loss: 0.4121 - val_accuracy: 0.8951\n",
      "Epoch 45/400\n",
      "3658/3658 [==============================] - 1s 180us/sample - loss: 0.5163 - accuracy: 0.7701 - val_loss: 0.4125 - val_accuracy: 0.8973\n",
      "Epoch 46/400\n",
      "3658/3658 [==============================] - 1s 162us/sample - loss: 0.5274 - accuracy: 0.7783 - val_loss: 0.4501 - val_accuracy: 0.8852\n",
      "Epoch 47/400\n",
      "3658/3658 [==============================] - 1s 186us/sample - loss: 0.5343 - accuracy: 0.7701 - val_loss: 0.5128 - val_accuracy: 0.8536\n",
      "Epoch 48/400\n",
      "3658/3658 [==============================] - 1s 151us/sample - loss: 0.5055 - accuracy: 0.7783 - val_loss: 0.3836 - val_accuracy: 0.9049\n",
      "Epoch 49/400\n",
      "3658/3658 [==============================] - 1s 191us/sample - loss: 0.5291 - accuracy: 0.7739 - val_loss: 0.4527 - val_accuracy: 0.8852\n",
      "Epoch 50/400\n",
      "3658/3658 [==============================] - 1s 176us/sample - loss: 0.5064 - accuracy: 0.7734 - val_loss: 0.3760 - val_accuracy: 0.9115\n",
      "Epoch 51/400\n",
      "3658/3658 [==============================] - 1s 171us/sample - loss: 0.5085 - accuracy: 0.7742 - val_loss: 0.3946 - val_accuracy: 0.9027\n",
      "Epoch 52/400\n",
      "3658/3658 [==============================] - 1s 163us/sample - loss: 0.5144 - accuracy: 0.7750 - val_loss: 0.2817 - val_accuracy: 0.9508\n",
      "Epoch 53/400\n",
      "3658/3658 [==============================] - 1s 163us/sample - loss: 0.5039 - accuracy: 0.7745 - val_loss: 0.3663 - val_accuracy: 0.9126\n",
      "Epoch 54/400\n",
      "3658/3658 [==============================] - 1s 164us/sample - loss: 0.4977 - accuracy: 0.7827 - val_loss: 0.3397 - val_accuracy: 0.9246\n",
      "Epoch 55/400\n",
      "3658/3658 [==============================] - 1s 166us/sample - loss: 0.5192 - accuracy: 0.7780 - val_loss: 0.3579 - val_accuracy: 0.9224\n",
      "Epoch 56/400\n",
      "3658/3658 [==============================] - 1s 160us/sample - loss: 0.5078 - accuracy: 0.7649 - val_loss: 0.4712 - val_accuracy: 0.8721\n",
      "Epoch 57/400\n",
      "3658/3658 [==============================] - 1s 171us/sample - loss: 0.5251 - accuracy: 0.7712 - val_loss: 0.4227 - val_accuracy: 0.8885\n",
      "Epoch 58/400\n",
      "3658/3658 [==============================] - 1s 165us/sample - loss: 0.5249 - accuracy: 0.7772 - val_loss: 0.3771 - val_accuracy: 0.9093\n",
      "Epoch 59/400\n",
      "3658/3658 [==============================] - 1s 176us/sample - loss: 0.5124 - accuracy: 0.7780 - val_loss: 0.3574 - val_accuracy: 0.9137\n",
      "Epoch 60/400\n",
      "3658/3658 [==============================] - 1s 162us/sample - loss: 0.5156 - accuracy: 0.7734 - val_loss: 0.5010 - val_accuracy: 0.8645\n",
      "Epoch 61/400\n",
      "3658/3658 [==============================] - 1s 181us/sample - loss: 0.5185 - accuracy: 0.7717 - val_loss: 0.4455 - val_accuracy: 0.8852\n",
      "Epoch 62/400\n",
      "3658/3658 [==============================] - 1s 181us/sample - loss: 0.5219 - accuracy: 0.7690 - val_loss: 0.3286 - val_accuracy: 0.9410\n",
      "Epoch 63/400\n",
      "3658/3658 [==============================] - 1s 195us/sample - loss: 0.4983 - accuracy: 0.7775 - val_loss: 0.4082 - val_accuracy: 0.8962\n",
      "Epoch 64/400\n",
      "3658/3658 [==============================] - 1s 219us/sample - loss: 0.5086 - accuracy: 0.7701 - val_loss: 0.4059 - val_accuracy: 0.9005\n",
      "Epoch 65/400\n",
      "3658/3658 [==============================] - 1s 239us/sample - loss: 0.5175 - accuracy: 0.7742 - val_loss: 0.4886 - val_accuracy: 0.8667\n",
      "Epoch 66/400\n",
      "3658/3658 [==============================] - 1s 235us/sample - loss: 0.5330 - accuracy: 0.7685 - val_loss: 0.5020 - val_accuracy: 0.8612\n",
      "Epoch 67/400\n",
      "3658/3658 [==============================] - 1s 226us/sample - loss: 0.5078 - accuracy: 0.7758 - val_loss: 0.3858 - val_accuracy: 0.9082\n",
      "Epoch 68/400\n",
      "3658/3658 [==============================] - 1s 274us/sample - loss: 0.5271 - accuracy: 0.7780 - val_loss: 0.5140 - val_accuracy: 0.8590\n",
      "Epoch 69/400\n",
      "3658/3658 [==============================] - 3s 755us/sample - loss: 0.5145 - accuracy: 0.7745 - val_loss: 0.4122 - val_accuracy: 0.8973\n",
      "Epoch 70/400\n",
      "3658/3658 [==============================] - 3s 706us/sample - loss: 0.5392 - accuracy: 0.7668 - val_loss: 0.3868 - val_accuracy: 0.9191\n",
      "Epoch 71/400\n",
      "3658/3658 [==============================] - 3s 720us/sample - loss: 0.5131 - accuracy: 0.7723 - val_loss: 0.3276 - val_accuracy: 0.9322\n",
      "Epoch 72/400\n",
      "3658/3658 [==============================] - 2s 579us/sample - loss: 0.5086 - accuracy: 0.7808 - val_loss: 0.4894 - val_accuracy: 0.8656\n",
      "Epoch 73/400\n",
      "3658/3658 [==============================] - 1s 330us/sample - loss: 0.5141 - accuracy: 0.7788 - val_loss: 0.3846 - val_accuracy: 0.9093\n",
      "Epoch 74/400\n",
      "3658/3658 [==============================] - 1s 256us/sample - loss: 0.5182 - accuracy: 0.7712 - val_loss: 0.4050 - val_accuracy: 0.8929\n",
      "Epoch 75/400\n",
      "3658/3658 [==============================] - 1s 223us/sample - loss: 0.5059 - accuracy: 0.7753 - val_loss: 0.3990 - val_accuracy: 0.8995\n",
      "Epoch 76/400\n",
      "3658/3658 [==============================] - 1s 184us/sample - loss: 0.5065 - accuracy: 0.7756 - val_loss: 0.3652 - val_accuracy: 0.9115\n",
      "Epoch 77/400\n",
      "3658/3658 [==============================] - 1s 164us/sample - loss: 0.5205 - accuracy: 0.7734 - val_loss: 0.3629 - val_accuracy: 0.9126\n",
      "Epoch 78/400\n",
      "3658/3658 [==============================] - 1s 163us/sample - loss: 0.5166 - accuracy: 0.7745 - val_loss: 0.3060 - val_accuracy: 0.9475\n",
      "Epoch 79/400\n",
      "3632/3658 [============================>.] - ETA: 0s - loss: 0.5119 - accuracy: 0.7737\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3658/3658 [==============================] - 1s 181us/sample - loss: 0.5114 - accuracy: 0.7736 - val_loss: 0.3800 - val_accuracy: 0.9082\n",
      "Epoch 80/400\n",
      "3658/3658 [==============================] - 1s 184us/sample - loss: 0.5058 - accuracy: 0.7799 - val_loss: 0.3601 - val_accuracy: 0.9082\n",
      "Epoch 81/400\n",
      "3658/3658 [==============================] - 1s 182us/sample - loss: 0.5125 - accuracy: 0.7638 - val_loss: 0.3404 - val_accuracy: 0.9224\n",
      "Epoch 82/400\n",
      "3658/3658 [==============================] - 1s 182us/sample - loss: 0.5030 - accuracy: 0.7756 - val_loss: 0.3326 - val_accuracy: 0.9333\n",
      "Epoch 83/400\n",
      "3658/3658 [==============================] - 1s 184us/sample - loss: 0.5103 - accuracy: 0.7712 - val_loss: 0.3514 - val_accuracy: 0.9366\n",
      "Epoch 84/400\n",
      "3658/3658 [==============================] - 1s 208us/sample - loss: 0.4961 - accuracy: 0.7695 - val_loss: 0.3607 - val_accuracy: 0.9213\n",
      "Epoch 85/400\n",
      "3658/3658 [==============================] - 1s 267us/sample - loss: 0.5058 - accuracy: 0.7687 - val_loss: 0.3858 - val_accuracy: 0.9115\n",
      "Epoch 86/400\n",
      "3658/3658 [==============================] - 1s 226us/sample - loss: 0.5022 - accuracy: 0.7736 - val_loss: 0.3666 - val_accuracy: 0.9202\n",
      "Epoch 87/400\n",
      "3658/3658 [==============================] - 1s 201us/sample - loss: 0.5062 - accuracy: 0.7780 - val_loss: 0.4245 - val_accuracy: 0.8885\n",
      "Epoch 88/400\n",
      "3658/3658 [==============================] - 1s 230us/sample - loss: 0.4995 - accuracy: 0.7761 - val_loss: 0.4938 - val_accuracy: 0.8645\n",
      "Epoch 89/400\n",
      "3658/3658 [==============================] - 1s 236us/sample - loss: 0.5082 - accuracy: 0.7728 - val_loss: 0.3902 - val_accuracy: 0.8995\n",
      "Epoch 90/400\n",
      "3658/3658 [==============================] - 1s 233us/sample - loss: 0.5097 - accuracy: 0.7731 - val_loss: 0.4203 - val_accuracy: 0.8951\n",
      "Epoch 91/400\n",
      "3658/3658 [==============================] - 1s 236us/sample - loss: 0.4987 - accuracy: 0.7786 - val_loss: 0.3935 - val_accuracy: 0.9005\n",
      "Epoch 92/400\n",
      "3658/3658 [==============================] - 1s 233us/sample - loss: 0.5027 - accuracy: 0.7739 - val_loss: 0.4143 - val_accuracy: 0.8874\n",
      "Epoch 00092: early stopping\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-141c7850605c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"valid_score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input,Conv1D, Activation, GlobalMaxPooling1D, BatchNormalization, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inp=Input(shape=(16,1))\n",
    "conv=Conv1D(1, 3, use_bias=False, name='conv1')(inp)\n",
    "conv=GlobalMaxPooling1D()(conv)\n",
    "conv = BatchNormalization(momentum=0.8)(conv)\n",
    "# conv=Activation('sigmoid')(conv)\n",
    "# conv=Dense(1,use_bias=True, activation='sigmoid')(conv)\n",
    "conv=Dense(1,use_bias=True)(conv)\n",
    "model=Model(inputs=inp,outputs=conv)\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "filepath=r'/home/sgr/Загрузки/coh_model_simple1.h5'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', mode='min', patience=40, verbose=1)\n",
    "mcp_save = ModelCheckpoint(filepath, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=25, verbose=1, min_delta=1e-4, mode='min')\n",
    "\n",
    "model.fit(X, y, batch_size=16, epochs=400, verbose=1, callbacks=[earlyStopping, mcp_save,reduce_lr_loss], validation_split=0.2)\n",
    "\n",
    "# model.fit(X, y, batch_size=16, epochs=400, verbose=1, callbacks=[mcp_save,reduce_lr_loss], validation_split=0.2)\n",
    "\n",
    "# model.load_weights(filepath)\n",
    "\n",
    "\n",
    "print(\"train_score\", model.evaluate(x_train, y_train, batch_size=16, verbose=2))\n",
    "print(\"valid_score\", model.evaluate(x_test, y_test, batch_size=16, verbose=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3213/1 - 1s - loss: 0.3997 - accuracy: 0.7700\n",
      "train_score [0.514445650319685, 0.7699969]\n"
     ]
    }
   ],
   "source": [
    "print(\"train_score\", model.evaluate(X, y, batch_size=16, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "one_ind=np.random.choice(np.where(y==1)[0])\n",
    "zero_ind=np.random.choice(np.where(y==0)[0])\n",
    "\n",
    "for num, (line_id, name) in enumerate(zip([one_ind, zero_ind],['one','using'])):\n",
    "    plt.subplot(1,2,num+1)\n",
    "    plt.bar(np.arange(16),X[line_id][:,0])\n",
    "    plt.title(f'{name} {y[line_id]}/{y_pred[line_id][0]:.2f}')\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23055188]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=np.full([16,1], 0.2)\n",
    "# test[-1]=0.6\n",
    "test[-1]=0.7\n",
    "model.predict(test[None,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(bin_arr):\n",
    "    ln=bin_arr.shape[0]\n",
    "    ones=np.sum(bin_arr.flatten())\n",
    "    zeros=ln-ones\n",
    "    if ones*zeros==0:return 0\n",
    "    return -ones/ln*np.log2(ones/ln)-zeros/ln*np.log2(zeros/ln)\n",
    "\n",
    "def conv1d(arr, kernel):    \n",
    "    arr=arr.flatten()\n",
    "    kernel=kernel.flatten()\n",
    "    lenn=kernel.shape[0]    \n",
    "    arlen=arr.shape[0]\n",
    "    outt=[]\n",
    "    for i in range(lenn):\n",
    "        outt.append(arr[i:arlen-(lenn-i-1)])\n",
    "    return np.array(outt).T.dot(kernel)\n",
    "batch_conv1d = np.vectorize(conv1d, signature='(n,m),(k)->(l)')\n",
    "\n",
    "correlate = np.vectorize(np.correlate, signature='(n),(m)->(k)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=np.random.rand(20,16,1)\n",
    "test_y=np.random.randint(0,2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 16, 1), (20,))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape,test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3213, 16, 1), (3213,))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.00000000e+00, -9.00000000e-01, -8.00000000e-01, -7.00000000e-01,\n",
       "       -6.00000000e-01, -5.00000000e-01, -4.00000000e-01, -3.00000000e-01,\n",
       "       -2.00000000e-01, -1.00000000e-01, -2.22044605e-16,  1.00000000e-01,\n",
       "        2.00000000e-01,  3.00000000e-01,  4.00000000e-01,  5.00000000e-01,\n",
       "        6.00000000e-01,  7.00000000e-01,  8.00000000e-01,  9.00000000e-01,\n",
       "        1.00000000e+00])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(-1,1.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "best=0\n",
    "params={}\n",
    "\n",
    "\n",
    "X_tr=np.random.rand(3000,16,1)\n",
    "y_tr=np.random.randint(0,2,3000)\n",
    "\n",
    "for i in np.arange(-1,1.1,0.1):\n",
    "    for j in np.arange(-1,1.1,0.1):\n",
    "#         for ij in np.arange(-1,1.1,0.1):\n",
    "\n",
    "#         kernel=[-0.4,0.6]\n",
    "        kernel=[i,j]\n",
    "        conved=batch_conv1d(X_tr, kernel)\n",
    "        maxx=conved.max(axis=1)\n",
    "        maxx[np.argsort(conved)]\n",
    "\n",
    "        sorted_y=y_tr[np.argsort(maxx)]\n",
    "        sorted_feat=np.sort(maxx)\n",
    "\n",
    "        beg_entr=entropy(sorted_y)\n",
    "        cut_val=0\n",
    "\n",
    "        cut_ind=0\n",
    "\n",
    "        arr_len=sorted_y.shape[0]\n",
    "        for ind in range(1, sorted_y.shape[0]):\n",
    "            if sorted_y[ind]==sorted_y[ind-1]: continue\n",
    "            left= sorted_y[:ind]  \n",
    "            right= sorted_y[ind:]\n",
    "            l_ent=entropy(left)\n",
    "            r_ent=entropy(right)    \n",
    "            cur_entr= (ind-1)/arr_len*l_ent+(arr_len-ind-1)/arr_len*r_ent                \n",
    "\n",
    "            if cur_entr< beg_entr:\n",
    "                beg_entr=cur_entr\n",
    "                cut_val=(sorted_feat[ind-1]+sorted_feat[ind])/2\n",
    "                cut_ind=ind\n",
    "        compare_arr=np.zeros(arr_len)\n",
    "        compare_arr[:cut_ind]=1\n",
    "        asses=np.sum(compare_arr==sorted_y)/arr_len\n",
    "        if asses>best:\n",
    "            best=asses\n",
    "            params['cut_val']=cut_val\n",
    "            params['cut_ind']=cut_ind \n",
    "            params['beg_entr']=beg_entr\n",
    "            params['kernel']=kernel\n",
    "\n",
    "#         np.sum(compare_arr==sorted_y)/arr_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cut_val': 0.02563241338200064,\n",
       "  'cut_ind': 1740,\n",
       "  'beg_entr': 0.995278216939246,\n",
       "  'kernel': [0.09999999999999964, -0.8]},\n",
       " 0.5373333333333333)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7952069716775599"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7285044293903075, 0.15931941221964424)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(sorted_y[:cut_ind])/cut_ind, np.sum(sorted_y[cut_ind:])/(arr_len-cut_ind-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33715315, 0.3726555 , 0.3818512 , 0.41187758, 0.42491575,\n",
       "       0.43830487, 0.44651313, 0.44728139, 0.4492165 , 0.45072506,\n",
       "       0.45315965, 0.47120151, 0.48562152, 0.48633297, 0.48824995,\n",
       "       0.50583116, 0.50998889, 0.54502015, 0.56594494, 0.5768519 ])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5079100249999999"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.50583116+0.50998889)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 15)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conved.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 15)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_conv1d(test_X, [0.2,0.5]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194 µs ± 5.47 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "batch_conv1d(test_X, [0.2,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 µs ± 3.66 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "correlate(test_X[:,:,0],[0.2,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2570 samples, validate on 643 samples\n",
      "Epoch 1/400\n",
      "2570/2570 [==============================] - 1s 338us/sample - loss: 0.6124 - accuracy: 0.6393 - val_loss: 0.6411 - val_accuracy: 0.8087\n",
      "Epoch 2/400\n",
      "2570/2570 [==============================] - 0s 156us/sample - loss: 0.4742 - accuracy: 0.7700 - val_loss: 0.7239 - val_accuracy: 0.7030\n",
      "Epoch 3/400\n",
      "2570/2570 [==============================] - 0s 179us/sample - loss: 0.4452 - accuracy: 0.7774 - val_loss: 0.7410 - val_accuracy: 0.6703\n",
      "Epoch 4/400\n",
      "2570/2570 [==============================] - 1s 195us/sample - loss: 0.4377 - accuracy: 0.7840 - val_loss: 0.6963 - val_accuracy: 0.7061\n",
      "Epoch 5/400\n",
      "2570/2570 [==============================] - 1s 208us/sample - loss: 0.4287 - accuracy: 0.7899 - val_loss: 0.6068 - val_accuracy: 0.7714\n",
      "Epoch 6/400\n",
      "2570/2570 [==============================] - 1s 241us/sample - loss: 0.4332 - accuracy: 0.7903 - val_loss: 0.5196 - val_accuracy: 0.8149\n",
      "Epoch 7/400\n",
      "2570/2570 [==============================] - 0s 149us/sample - loss: 0.4251 - accuracy: 0.7969 - val_loss: 0.5837 - val_accuracy: 0.7947\n",
      "Epoch 8/400\n",
      "2570/2570 [==============================] - 0s 151us/sample - loss: 0.4183 - accuracy: 0.7973 - val_loss: 0.5731 - val_accuracy: 0.7994\n",
      "Epoch 9/400\n",
      "2570/2570 [==============================] - 0s 186us/sample - loss: 0.4182 - accuracy: 0.7977 - val_loss: 0.6756 - val_accuracy: 0.7387\n",
      "Epoch 10/400\n",
      "2570/2570 [==============================] - 0s 185us/sample - loss: 0.4129 - accuracy: 0.7977 - val_loss: 0.5764 - val_accuracy: 0.8009\n",
      "Epoch 11/400\n",
      "2570/2570 [==============================] - 0s 186us/sample - loss: 0.4154 - accuracy: 0.8000 - val_loss: 0.5891 - val_accuracy: 0.7932\n",
      "Epoch 12/400\n",
      "2570/2570 [==============================] - 1s 205us/sample - loss: 0.4088 - accuracy: 0.8082 - val_loss: 0.5967 - val_accuracy: 0.7900\n",
      "Epoch 13/400\n",
      "2570/2570 [==============================] - 1s 205us/sample - loss: 0.4122 - accuracy: 0.7973 - val_loss: 0.7438 - val_accuracy: 0.7372\n",
      "Epoch 14/400\n",
      "2570/2570 [==============================] - 1s 218us/sample - loss: 0.4106 - accuracy: 0.8019 - val_loss: 0.6766 - val_accuracy: 0.7512\n",
      "Epoch 15/400\n",
      "2570/2570 [==============================] - 1s 209us/sample - loss: 0.4077 - accuracy: 0.8089 - val_loss: 0.5171 - val_accuracy: 0.8149\n",
      "Epoch 16/400\n",
      "2570/2570 [==============================] - 0s 194us/sample - loss: 0.4063 - accuracy: 0.8047 - val_loss: 0.6051 - val_accuracy: 0.7714\n",
      "Epoch 17/400\n",
      "2570/2570 [==============================] - 0s 178us/sample - loss: 0.4097 - accuracy: 0.7984 - val_loss: 0.8159 - val_accuracy: 0.6874\n",
      "Epoch 18/400\n",
      "2570/2570 [==============================] - 0s 184us/sample - loss: 0.4039 - accuracy: 0.8031 - val_loss: 0.6274 - val_accuracy: 0.7776\n",
      "Epoch 19/400\n",
      "2570/2570 [==============================] - 0s 173us/sample - loss: 0.4037 - accuracy: 0.8051 - val_loss: 0.6796 - val_accuracy: 0.7465\n",
      "Epoch 20/400\n",
      "2570/2570 [==============================] - 0s 181us/sample - loss: 0.4003 - accuracy: 0.8132 - val_loss: 0.4665 - val_accuracy: 0.8351\n",
      "Epoch 21/400\n",
      "2570/2570 [==============================] - 0s 150us/sample - loss: 0.4003 - accuracy: 0.8082 - val_loss: 0.7153 - val_accuracy: 0.7107\n",
      "Epoch 22/400\n",
      "2570/2570 [==============================] - 0s 159us/sample - loss: 0.4053 - accuracy: 0.8093 - val_loss: 0.6075 - val_accuracy: 0.7807\n",
      "Epoch 23/400\n",
      "2570/2570 [==============================] - 0s 178us/sample - loss: 0.3929 - accuracy: 0.8121 - val_loss: 0.6917 - val_accuracy: 0.7387\n",
      "Epoch 24/400\n",
      "2570/2570 [==============================] - 0s 170us/sample - loss: 0.3957 - accuracy: 0.8144 - val_loss: 0.6122 - val_accuracy: 0.7698\n",
      "Epoch 25/400\n",
      "2570/2570 [==============================] - 0s 168us/sample - loss: 0.3924 - accuracy: 0.8144 - val_loss: 0.6519 - val_accuracy: 0.7698\n",
      "Epoch 26/400\n",
      "2570/2570 [==============================] - 0s 171us/sample - loss: 0.3878 - accuracy: 0.8062 - val_loss: 0.6365 - val_accuracy: 0.7527\n",
      "Epoch 27/400\n",
      "2570/2570 [==============================] - 1s 205us/sample - loss: 0.3896 - accuracy: 0.8152 - val_loss: 0.4790 - val_accuracy: 0.8460\n",
      "Epoch 28/400\n",
      "2570/2570 [==============================] - 0s 184us/sample - loss: 0.3861 - accuracy: 0.8175 - val_loss: 0.8125 - val_accuracy: 0.6952\n",
      "Epoch 29/400\n",
      "2570/2570 [==============================] - 0s 172us/sample - loss: 0.3899 - accuracy: 0.8160 - val_loss: 0.7515 - val_accuracy: 0.7216\n",
      "Epoch 30/400\n",
      "2570/2570 [==============================] - 0s 178us/sample - loss: 0.3865 - accuracy: 0.8148 - val_loss: 0.5231 - val_accuracy: 0.8274\n",
      "Epoch 31/400\n",
      "2570/2570 [==============================] - 0s 185us/sample - loss: 0.3865 - accuracy: 0.8156 - val_loss: 0.5330 - val_accuracy: 0.8212\n",
      "Epoch 32/400\n",
      "2570/2570 [==============================] - 1s 198us/sample - loss: 0.3842 - accuracy: 0.8152 - val_loss: 0.7922 - val_accuracy: 0.7061\n",
      "Epoch 33/400\n",
      "2570/2570 [==============================] - 1s 208us/sample - loss: 0.3810 - accuracy: 0.8218 - val_loss: 0.7981 - val_accuracy: 0.7092\n",
      "Epoch 34/400\n",
      "2570/2570 [==============================] - 1s 214us/sample - loss: 0.3763 - accuracy: 0.8280 - val_loss: 0.6973 - val_accuracy: 0.7449\n",
      "Epoch 35/400\n",
      "2570/2570 [==============================] - 0s 187us/sample - loss: 0.3766 - accuracy: 0.8222 - val_loss: 0.6283 - val_accuracy: 0.7558\n",
      "Epoch 36/400\n",
      "2570/2570 [==============================] - 0s 189us/sample - loss: 0.3738 - accuracy: 0.8268 - val_loss: 0.6198 - val_accuracy: 0.7807\n",
      "Epoch 37/400\n",
      "2570/2570 [==============================] - 1s 206us/sample - loss: 0.3779 - accuracy: 0.8202 - val_loss: 0.6180 - val_accuracy: 0.7760\n",
      "Epoch 38/400\n",
      "2570/2570 [==============================] - 1s 201us/sample - loss: 0.3733 - accuracy: 0.8288 - val_loss: 0.5472 - val_accuracy: 0.8072\n",
      "Epoch 39/400\n",
      "2570/2570 [==============================] - 1s 209us/sample - loss: 0.3712 - accuracy: 0.8304 - val_loss: 0.7145 - val_accuracy: 0.7418\n",
      "Epoch 40/400\n",
      "2570/2570 [==============================] - 1s 210us/sample - loss: 0.3717 - accuracy: 0.8214 - val_loss: 0.7406 - val_accuracy: 0.7138\n",
      "Epoch 00040: early stopping\n",
      "2570/1 - 0s - loss: 0.4303 - accuracy: 0.8109\n",
      "train_score [0.41867522933603724, 0.81089497]\n",
      "643/1 - 0s - loss: 0.2662 - accuracy: 0.8134\n",
      "valid_score [0.3999227268467795, 0.8133748]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# inp=Input(input_shape=(16,1))\n",
    "\n",
    "model.add(Conv1D(40, 2, activation='relu', input_shape=(16,1)))\n",
    "model.add(Conv1D(40, 2, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(80, 3, activation='relu'))\n",
    "model.add(Conv1D(160, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam')\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "filepath=r'/home/sgr/Загрузки/coh_model1.h5'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1)\n",
    "mcp_save = ModelCheckpoint(filepath, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=15, verbose=1, min_delta=1e-4, mode='min')\n",
    "\n",
    "model.fit(X, y, batch_size=16, epochs=400, verbose=1, callbacks=[earlyStopping, mcp_save,reduce_lr_loss], validation_split=0.2)\n",
    "\n",
    "\n",
    "# model.fit(x_train, y_train, batch_size=16, epochs=80)\n",
    "model.load_weights(filepath)\n",
    "print(\"train_score\", model.evaluate(x_train, y_train, batch_size=16, verbose=2))\n",
    "print(\"valid_score\", model.evaluate(x_test, y_test, batch_size=16, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "# del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv1d_245_input_1:0' shape=(None, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.6176 - acc: 0.6470\n",
      "Epoch 2/40\n",
      "3569/3569 [==============================] - 2s 458us/step - loss: 0.4623 - acc: 0.7795\n",
      "Epoch 3/40\n",
      "3569/3569 [==============================] - 2s 486us/step - loss: 0.4118 - acc: 0.8100\n",
      "Epoch 4/40\n",
      "3569/3569 [==============================] - 3s 830us/step - loss: 0.4009 - acc: 0.8187\n",
      "Epoch 5/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.3837 - acc: 0.8299\n",
      "Epoch 6/40\n",
      "3569/3569 [==============================] - 5s 2ms/step - loss: 0.3751 - acc: 0.8282\n",
      "Epoch 7/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.3532 - acc: 0.8451\n",
      "Epoch 8/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.3544 - acc: 0.8434\n",
      "Epoch 9/40\n",
      "3569/3569 [==============================] - 8s 2ms/step - loss: 0.3385 - acc: 0.8551\n",
      "Epoch 10/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.3305 - acc: 0.8565\n",
      "Epoch 11/40\n",
      "3569/3569 [==============================] - 5s 2ms/step - loss: 0.3229 - acc: 0.8557\n",
      "Epoch 12/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.3096 - acc: 0.8720\n",
      "Epoch 13/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.3084 - acc: 0.8672\n",
      "Epoch 14/40\n",
      "3569/3569 [==============================] - 4s 989us/step - loss: 0.2940 - acc: 0.8795\n",
      "Epoch 15/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.2742 - acc: 0.8857\n",
      "Epoch 16/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.2732 - acc: 0.8902\n",
      "Epoch 17/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.2622 - acc: 0.8893\n",
      "Epoch 18/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.2607 - acc: 0.8907\n",
      "Epoch 19/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.2527 - acc: 0.9019\n",
      "Epoch 20/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.2482 - acc: 0.8991\n",
      "Epoch 21/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.2375 - acc: 0.9031\n",
      "Epoch 22/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.2308 - acc: 0.9078\n",
      "Epoch 23/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.2286 - acc: 0.9148\n",
      "Epoch 24/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.2119 - acc: 0.9140\n",
      "Epoch 25/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.2070 - acc: 0.9171\n",
      "Epoch 26/40\n",
      "3569/3569 [==============================] - 4s 995us/step - loss: 0.2041 - acc: 0.9190\n",
      "Epoch 27/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.1853 - acc: 0.9257\n",
      "Epoch 28/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.1892 - acc: 0.9252\n",
      "Epoch 29/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.1850 - acc: 0.9325\n",
      "Epoch 30/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.1797 - acc: 0.9328\n",
      "Epoch 31/40\n",
      "3569/3569 [==============================] - 5s 2ms/step - loss: 0.1780 - acc: 0.9302\n",
      "Epoch 32/40\n",
      "3569/3569 [==============================] - 3s 972us/step - loss: 0.1848 - acc: 0.9274\n",
      "Epoch 33/40\n",
      "3569/3569 [==============================] - 7s 2ms/step - loss: 0.1795 - acc: 0.9350\n",
      "Epoch 34/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.1653 - acc: 0.9358\n",
      "Epoch 35/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.1600 - acc: 0.9417\n",
      "Epoch 36/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.1517 - acc: 0.9395\n",
      "Epoch 37/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.1590 - acc: 0.9414\n",
      "Epoch 38/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.1519 - acc: 0.9426\n",
      "Epoch 39/40\n",
      "3569/3569 [==============================] - 3s 913us/step - loss: 0.1587 - acc: 0.9456\n",
      "Epoch 40/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.1476 - acc: 0.9445\n",
      "893/893 [==============================] - 1s 1ms/step\n",
      "3569/3569 [==============================] - 1s 214us/step\n",
      "train_score [0.08684802611490765, 0.9731017091622303]\n",
      "valid_score [0.3272134645655334, 0.8992161254866793]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "arr=gg[['vv','vh']].values\n",
    "ii=np.array([np.array([i[0],i[1]]) for i in arr])\n",
    "X=np.swapaxes(ii, 1, 2)\n",
    "\n",
    "#trim 2 first vals for vv, vh\n",
    "X=X[:,2:,:]\n",
    "\n",
    "\n",
    "y=gg['cl'].astype(int).values\n",
    "y=np.reshape(y,(y.size,1))\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(40, 2, activation='relu', input_shape=(15, 2)))\n",
    "model.add(Conv1D(40, 2, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(80, 3, activation='relu'))\n",
    "model.add(Conv1D(160, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=40)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)\n",
    "print(\"train_score\", model.evaluate(x_train, y_train, batch_size=16))\n",
    "print(\"valid_score\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(r\"/home/sgr/Загрузки/SXuynia/model/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(r\"/home/sgr/Загрузки/SXuynia/model/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction on tf record dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/arrsent1_2019-00000.tfrecord.gz', 'data/arrsent1_2019-00001.tfrecord.gz', 'data/arrsent1_2019-00002.tfrecord.gz', 'data/arrsent1_2019-00003.tfrecord.gz', 'data/arrsent1_2019-00004.tfrecord.gz', 'data/arrsent1_2019-00005.tfrecord.gz', 'data/arrsent1_2019-00006.tfrecord.gz', 'data/arrsent1_2019-00007.tfrecord.gz', 'data/arrsent1_2019-00008.tfrecord.gz', 'data/arrsent1_2019-00009.tfrecord.gz', 'data/arrsent1_2019-00010.tfrecord.gz', 'data/arrsent1_2019-00011.tfrecord.gz', 'data/arrsent1_2019-00012.tfrecord.gz', 'data/arrsent1_2019-00013.tfrecord.gz', 'data/arrsent1_2019-00014.tfrecord.gz', 'data/arrsent1_2019-00015.tfrecord.gz', 'data/arrsent1_2019-00016.tfrecord.gz', 'data/arrsent1_2019-00017.tfrecord.gz', 'data/arrsent1_2019-00018.tfrecord.gz', 'data/arrsent1_2019-00019.tfrecord.gz', 'data/arrsent1_2019-00020.tfrecord.gz', 'data/arrsent1_2019-00021.tfrecord.gz']\n",
      "data/arrsent1_2019-mixer.json\n",
      "{'projection': {'crs': 'EPSG:32635', 'affine': {'doubleMatrix': [20.0, 0.0, 567680.0, 0.0, -20.0, 6223500.0]}}, 'patchDimensions': [256, 256], 'patchesPerRow': 19, 'totalPatches': 513}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# json_file1='data/arrsent1_2018-mixer.json'\n",
    "OUTPUT_BUCKET='data'\n",
    "IMAGE_FILE_PREFIX='arrsent1_2019'\n",
    "\n",
    "# Get a list of all the files in the output bucket.\n",
    "files_list = !ls {OUTPUT_BUCKET}\n",
    "# Get only the files generated by the image export.\n",
    "exported_files_list = [s for s in files_list if IMAGE_FILE_PREFIX in s]\n",
    "\n",
    "# Get the list of image files and the JSON mixer file.\n",
    "image_files_list = []\n",
    "json_file = None\n",
    "for f in exported_files_list:\n",
    "    if f.endswith('.tfrecord.gz'):\n",
    "        image_files_list.append(\"{0}/{1}\".format(OUTPUT_BUCKET,f))\n",
    "    elif f.endswith('.json'):\n",
    "        json_file = \"{0}/{1}\".format(OUTPUT_BUCKET,f)\n",
    "\n",
    "# Make sure the files are in the right order.\n",
    "image_files_list.sort()\n",
    "\n",
    "print(image_files_list)\n",
    "print(json_file)\n",
    "\n",
    "# Load the contents of the mixer file to a JSON object.\n",
    "json_text = !cat {json_file}\n",
    "# Get a single string w/ newlines from the IPython.utils.text.SList\n",
    "mixer = json.loads(json_text.nlstr)\n",
    "print(mixer)\n",
    "# print(json_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS=['s1_2019']\n",
    "\n",
    "patch_width = mixer['patchDimensions'][0]\n",
    "patch_height = mixer['patchDimensions'][1]\n",
    "patches = mixer['totalPatches']\n",
    "\n",
    "patch_dimensions_flat = [16,patch_width * patch_height]\n",
    "\n",
    "cols=mixer['patchesPerRow']\n",
    "rows=int(patches/cols)\n",
    "\n",
    "image_columns = [tf.io.FixedLenFeature(shape=patch_dimensions_flat, dtype=tf.float32) ]\n",
    "image_features_dict = dict(zip(BANDS, image_columns))\n",
    "# Note that you can make one dataset from many files by specifying a list.\n",
    "image_dataset = tf.data.TFRecordDataset(image_files_list, compression_type='GZIP')\n",
    "\n",
    "\n",
    "# Parsing function.\n",
    "def parse_image(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_features_dict)\n",
    "\n",
    "# Parse the data into tensors, one long tensor per patch.\n",
    "image_dataset = image_dataset.map(parse_image, num_parallel_calls=5)\n",
    "\n",
    "\n",
    "image_dataset = image_dataset.map(lambda features: tf.transpose(list(features.values())), num_parallel_calls=5)\n",
    "\n",
    "\n",
    "# Break our long tensors into many little ones.\n",
    "image_dataset = image_dataset.flat_map(\n",
    "  lambda features: tf.data.Dataset.from_tensor_slices(features)\n",
    ")\n",
    "\n",
    "# Turn each patch into a batch.\n",
    "image_dataset = image_dataset.batch(patch_width * patch_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513/513 [==============================] - 40s 77ms/step\n",
      "[0.92006546]\n",
      "(33619968, 1)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# Run prediction in batches, with as many steps as there are patches.\n",
    "predictions = model.predict(image_dataset, steps=patches, verbose=1)\n",
    "\n",
    "# Note that the predictions come as a numpy array.  Check the first one.\n",
    "print(predictions[0])\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions in TIFF tiles 1 tile per batch\n",
    "def save_as_tiff(predictions, mixer, out_dir):\n",
    "    from osgeo import gdal, osr\n",
    "    base_trans=mixer['projection']['affine']['doubleMatrix']\n",
    "    epsg=int(mixer['projection']['crs'].split(':')[1])\n",
    "    spref=osr.SpatialReference()\n",
    "    spref.ImportFromEPSG(epsg)\n",
    "    proj=tt.ExportToWkt()  \n",
    "    \n",
    "    patch_width = mixer['patchDimensions'][0]\n",
    "    patch_height = mixer['patchDimensions'][1]\n",
    "    patch_lens=patch_width*patch_height\n",
    "    patches = mixer['totalPatches'] \n",
    "    cols=mixer['patchesPerRow']\n",
    "    rows=int(patches/cols)\n",
    "\n",
    "    for i in range(patches):\n",
    "        row=i//cols\n",
    "        col=i%cols\n",
    "        dx=patch_width*col\n",
    "        dy=patch_width*row\n",
    "        trans=base_trans.copy()\n",
    "        trans[0]=base_trans[2]+base_trans[0]*dx\n",
    "        trans[1]=base_trans[0]\n",
    "        trans[2]=0\n",
    "        trans[3]=base_trans[-1]+base_trans[-2]*dy\n",
    "        trans[4]=0\n",
    "        trans[5]=base_trans[-2]\n",
    "        curar=predictions[i*patch_lens:(i+1)*patch_lens].reshape(mixer['patchDimensions'])\n",
    "        trans=tuple(trans)        \n",
    "        \n",
    "        to_path='%s/im_%04d.tif' % (out_dir,i)               \n",
    "        \n",
    "        driver = gdal.GetDriverByName('GTiff')\n",
    "        dataset = driver.Create(to_path, patch_width,\n",
    "                patch_height,\n",
    "                1,\n",
    "                gdal.GDT_Float32)\n",
    "#                                 , options=['COMPRESS=LZW'])\n",
    "        dataset.SetProjection(proj)\n",
    "        dataset.SetGeoTransform(trans)\n",
    "        \n",
    "        outband = dataset.GetRasterBand(1)\n",
    "        outband.WriteArray(curar)\n",
    "        dataset.FlushCache()\n",
    "        del dataset\n",
    "        del outband\n",
    "        del curar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir='data/out'\n",
    "save_as_tiff(predictions, mixer, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with patch 1 of 12...\n",
      "Done with patch 2 of 12...\n",
      "Done with patch 3 of 12...\n",
      "Done with patch 4 of 12...\n"
     ]
    }
   ],
   "source": [
    "# NOT NESSESARY Write to tfrecord\n",
    "\n",
    "OUTPUT_IMAGE_FILE='data/outt.TFRecord'\n",
    "writer = tf.io.TFRecordWriter(OUTPUT_IMAGE_FILE)\n",
    "\n",
    "# Every patch-worth of predictions we'll dump an example into the output\n",
    "# file with a single feature that holds our predictions. Since our predictions\n",
    "# are already in the order of the exported data, the patches we create here\n",
    "# will also be in the right order.\n",
    "patch = []\n",
    "cur_patch = 1\n",
    "for prediction in predictions:\n",
    "    patch.append(prediction)\n",
    "  \n",
    "  # Once we've seen a patches-worth of class_ids...\n",
    "    if (len(patch) == patch_width * patch_height):\n",
    "        print('Done with patch ' + str(cur_patch) + ' of ' + str(patches) + '...')\n",
    "        # Create an example\n",
    "        example = tf.train.Example(\n",
    "          features=tf.train.Features(\n",
    "            feature={\n",
    "              'prediction': tf.train.Feature(\n",
    "                  float_list=tf.train.FloatList(\n",
    "                      value=patch))\n",
    "            }\n",
    "          )\n",
    "        )\n",
    "        # Write the example to the file and clear our patch array so it's ready for\n",
    "        # another batch of class ids\n",
    "        writer.write(example.SerializeToString())\n",
    "        patch = []\n",
    "        cur_patch += 1\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
