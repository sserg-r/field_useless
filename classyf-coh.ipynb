{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(r'/home/sgr/Загрузки/feat_pnt_2018_coh_vhx2.xlsx')\n",
    "df2=pd.read_csv(r'/home/sgr/Загрузки/feat_pnt_2019_coh_vhx2.csv')\n",
    "mdf=df.append(df2,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del df2\n",
    "mdf['array']=mdf['array'].apply(lambda x:np.array(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "system:index     object\n",
       "array            object\n",
       "istarget          int64\n",
       ".geo            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.stack(mdf['array'].values)\n",
    "y=mdf['istarget'].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2570 samples, validate on 643 samples\n",
      "Epoch 1/400\n",
      "2570/2570 [==============================] - 1s 294us/sample - loss: 0.9870 - accuracy: 0.3813 - val_loss: 0.9930 - val_accuracy: 0.1742\n",
      "Epoch 2/400\n",
      "2570/2570 [==============================] - 0s 119us/sample - loss: 0.7528 - accuracy: 0.4961 - val_loss: 0.7797 - val_accuracy: 0.4168\n",
      "Epoch 3/400\n",
      "2570/2570 [==============================] - 0s 132us/sample - loss: 0.6187 - accuracy: 0.6553 - val_loss: 0.7036 - val_accuracy: 0.5490\n",
      "Epoch 4/400\n",
      "2570/2570 [==============================] - 0s 120us/sample - loss: 0.5473 - accuracy: 0.7195 - val_loss: 0.3770 - val_accuracy: 0.8896\n",
      "Epoch 5/400\n",
      "2570/2570 [==============================] - 0s 129us/sample - loss: 0.5024 - accuracy: 0.7447 - val_loss: 0.6675 - val_accuracy: 0.6532\n",
      "Epoch 6/400\n",
      "2570/2570 [==============================] - 0s 119us/sample - loss: 0.4785 - accuracy: 0.7681 - val_loss: 0.8144 - val_accuracy: 0.5054\n",
      "Epoch 7/400\n",
      "2570/2570 [==============================] - 0s 118us/sample - loss: 0.4600 - accuracy: 0.7790 - val_loss: 0.9931 - val_accuracy: 0.3935\n",
      "Epoch 8/400\n",
      "2570/2570 [==============================] - 0s 117us/sample - loss: 0.4456 - accuracy: 0.7872 - val_loss: 0.4663 - val_accuracy: 0.8165\n",
      "Epoch 9/400\n",
      "2570/2570 [==============================] - 0s 117us/sample - loss: 0.4371 - accuracy: 0.7899 - val_loss: 0.2806 - val_accuracy: 0.9020\n",
      "Epoch 10/400\n",
      "2570/2570 [==============================] - 0s 118us/sample - loss: 0.4430 - accuracy: 0.7899 - val_loss: 0.3529 - val_accuracy: 0.8818\n",
      "Epoch 11/400\n",
      "2570/2570 [==============================] - 0s 116us/sample - loss: 0.4298 - accuracy: 0.8016 - val_loss: 0.6501 - val_accuracy: 0.6921\n",
      "Epoch 12/400\n",
      "2570/2570 [==============================] - 0s 120us/sample - loss: 0.4301 - accuracy: 0.8016 - val_loss: 0.7132 - val_accuracy: 0.6470\n",
      "Epoch 13/400\n",
      "2570/2570 [==============================] - 0s 121us/sample - loss: 0.4262 - accuracy: 0.7946 - val_loss: 0.3535 - val_accuracy: 0.8740\n",
      "Epoch 14/400\n",
      "2570/2570 [==============================] - 0s 121us/sample - loss: 0.4150 - accuracy: 0.8031 - val_loss: 0.5041 - val_accuracy: 0.7854\n",
      "Epoch 15/400\n",
      "2570/2570 [==============================] - 0s 121us/sample - loss: 0.4265 - accuracy: 0.7977 - val_loss: 0.3455 - val_accuracy: 0.8663\n",
      "Epoch 16/400\n",
      "2570/2570 [==============================] - 0s 133us/sample - loss: 0.4171 - accuracy: 0.8070 - val_loss: 0.3895 - val_accuracy: 0.8585\n",
      "Epoch 17/400\n",
      "2570/2570 [==============================] - 0s 145us/sample - loss: 0.4134 - accuracy: 0.8043 - val_loss: 0.3219 - val_accuracy: 0.8849\n",
      "Epoch 18/400\n",
      "2570/2570 [==============================] - 0s 135us/sample - loss: 0.4324 - accuracy: 0.7984 - val_loss: 0.3338 - val_accuracy: 0.8756\n",
      "Epoch 19/400\n",
      "2570/2570 [==============================] - 0s 134us/sample - loss: 0.4112 - accuracy: 0.8093 - val_loss: 0.6079 - val_accuracy: 0.7232\n",
      "Epoch 20/400\n",
      "2570/2570 [==============================] - 0s 137us/sample - loss: 0.4155 - accuracy: 0.8019 - val_loss: 0.4840 - val_accuracy: 0.8009\n",
      "Epoch 21/400\n",
      "2570/2570 [==============================] - 0s 136us/sample - loss: 0.4158 - accuracy: 0.8054 - val_loss: 0.3433 - val_accuracy: 0.8709\n",
      "Epoch 22/400\n",
      "2570/2570 [==============================] - 0s 136us/sample - loss: 0.4162 - accuracy: 0.8066 - val_loss: 0.3161 - val_accuracy: 0.8896\n",
      "Epoch 23/400\n",
      "2570/2570 [==============================] - 0s 136us/sample - loss: 0.4224 - accuracy: 0.8012 - val_loss: 0.4634 - val_accuracy: 0.8056\n",
      "Epoch 24/400\n",
      "2570/2570 [==============================] - 0s 139us/sample - loss: 0.4154 - accuracy: 0.8086 - val_loss: 0.6320 - val_accuracy: 0.7154\n",
      "Epoch 25/400\n",
      "2570/2570 [==============================] - 0s 137us/sample - loss: 0.4149 - accuracy: 0.8082 - val_loss: 0.6108 - val_accuracy: 0.7201\n",
      "Epoch 26/400\n",
      "2570/2570 [==============================] - 0s 138us/sample - loss: 0.4111 - accuracy: 0.8121 - val_loss: 0.4245 - val_accuracy: 0.8320\n",
      "Epoch 27/400\n",
      "2570/2570 [==============================] - 0s 136us/sample - loss: 0.4110 - accuracy: 0.7984 - val_loss: 0.6961 - val_accuracy: 0.6719\n",
      "Epoch 28/400\n",
      "2570/2570 [==============================] - 0s 136us/sample - loss: 0.4228 - accuracy: 0.8008 - val_loss: 0.2848 - val_accuracy: 0.8989\n",
      "Epoch 29/400\n",
      "2570/2570 [==============================] - 0s 138us/sample - loss: 0.4149 - accuracy: 0.8039 - val_loss: 0.7516 - val_accuracy: 0.6516\n",
      "Epoch 30/400\n",
      "2570/2570 [==============================] - 0s 138us/sample - loss: 0.4130 - accuracy: 0.8101 - val_loss: 0.8199 - val_accuracy: 0.6034\n",
      "Epoch 31/400\n",
      "2570/2570 [==============================] - 0s 137us/sample - loss: 0.4207 - accuracy: 0.8078 - val_loss: 0.6050 - val_accuracy: 0.7403\n",
      "Epoch 32/400\n",
      "2570/2570 [==============================] - 0s 143us/sample - loss: 0.4097 - accuracy: 0.8148 - val_loss: 0.3190 - val_accuracy: 0.8911\n",
      "Epoch 33/400\n",
      "2570/2570 [==============================] - 0s 162us/sample - loss: 0.4134 - accuracy: 0.8093 - val_loss: 0.5056 - val_accuracy: 0.7823\n",
      "Epoch 34/400\n",
      "2570/2570 [==============================] - 0s 151us/sample - loss: 0.4131 - accuracy: 0.8086 - val_loss: 0.5317 - val_accuracy: 0.7714\n",
      "Epoch 35/400\n",
      "2570/2570 [==============================] - 0s 150us/sample - loss: 0.4113 - accuracy: 0.8125 - val_loss: 0.7215 - val_accuracy: 0.6563\n",
      "Epoch 36/400\n",
      "2570/2570 [==============================] - 0s 155us/sample - loss: 0.4180 - accuracy: 0.7996 - val_loss: 0.5718 - val_accuracy: 0.7496\n",
      "Epoch 37/400\n",
      "2570/2570 [==============================] - 0s 168us/sample - loss: 0.4165 - accuracy: 0.7953 - val_loss: 0.3373 - val_accuracy: 0.8880\n",
      "Epoch 38/400\n",
      "2570/2570 [==============================] - 0s 158us/sample - loss: 0.4166 - accuracy: 0.8023 - val_loss: 0.5825 - val_accuracy: 0.7449\n",
      "Epoch 39/400\n",
      "2570/2570 [==============================] - 0s 159us/sample - loss: 0.4166 - accuracy: 0.8074 - val_loss: 0.3584 - val_accuracy: 0.8756\n",
      "Epoch 40/400\n",
      "2570/2570 [==============================] - 0s 160us/sample - loss: 0.4169 - accuracy: 0.8086 - val_loss: 0.4538 - val_accuracy: 0.8196\n",
      "Epoch 41/400\n",
      "2570/2570 [==============================] - 0s 177us/sample - loss: 0.4176 - accuracy: 0.8004 - val_loss: 0.2720 - val_accuracy: 0.8989\n",
      "Epoch 42/400\n",
      "2570/2570 [==============================] - 0s 151us/sample - loss: 0.4113 - accuracy: 0.8082 - val_loss: 0.5196 - val_accuracy: 0.7823\n",
      "Epoch 43/400\n",
      "2570/2570 [==============================] - 0s 151us/sample - loss: 0.4132 - accuracy: 0.8051 - val_loss: 0.3985 - val_accuracy: 0.8507\n",
      "Epoch 44/400\n",
      "2570/2570 [==============================] - 0s 162us/sample - loss: 0.4152 - accuracy: 0.8125 - val_loss: 0.4544 - val_accuracy: 0.8180\n",
      "Epoch 45/400\n",
      "2570/2570 [==============================] - 0s 179us/sample - loss: 0.4216 - accuracy: 0.8012 - val_loss: 0.5358 - val_accuracy: 0.7667\n",
      "Epoch 46/400\n",
      "2570/2570 [==============================] - 0s 182us/sample - loss: 0.4053 - accuracy: 0.8082 - val_loss: 0.4389 - val_accuracy: 0.8243\n",
      "Epoch 47/400\n",
      "2570/2570 [==============================] - 0s 171us/sample - loss: 0.4054 - accuracy: 0.8101 - val_loss: 0.5948 - val_accuracy: 0.7434\n",
      "Epoch 48/400\n",
      "2570/2570 [==============================] - 0s 161us/sample - loss: 0.4249 - accuracy: 0.7984 - val_loss: 0.3521 - val_accuracy: 0.8725\n",
      "Epoch 49/400\n",
      "2570/2570 [==============================] - 0s 179us/sample - loss: 0.4061 - accuracy: 0.8101 - val_loss: 0.2796 - val_accuracy: 0.8974\n",
      "Epoch 50/400\n",
      "2570/2570 [==============================] - 0s 176us/sample - loss: 0.4087 - accuracy: 0.8082 - val_loss: 0.3769 - val_accuracy: 0.8569\n",
      "Epoch 51/400\n",
      "2570/2570 [==============================] - 0s 176us/sample - loss: 0.4239 - accuracy: 0.8058 - val_loss: 0.6263 - val_accuracy: 0.7263\n",
      "Epoch 52/400\n",
      "2570/2570 [==============================] - 0s 175us/sample - loss: 0.4171 - accuracy: 0.8078 - val_loss: 0.4013 - val_accuracy: 0.8351\n",
      "Epoch 53/400\n",
      "2570/2570 [==============================] - 0s 191us/sample - loss: 0.4048 - accuracy: 0.8113 - val_loss: 0.4136 - val_accuracy: 0.8336\n",
      "Epoch 54/400\n",
      "2570/2570 [==============================] - 0s 176us/sample - loss: 0.4134 - accuracy: 0.8097 - val_loss: 0.6785 - val_accuracy: 0.6890\n",
      "Epoch 55/400\n",
      "2570/2570 [==============================] - 0s 166us/sample - loss: 0.3871 - accuracy: 0.8218 - val_loss: 0.5100 - val_accuracy: 0.7947\n",
      "Epoch 56/400\n",
      "2570/2570 [==============================] - 0s 162us/sample - loss: 0.3904 - accuracy: 0.8261 - val_loss: 0.3502 - val_accuracy: 0.8802\n",
      "Epoch 57/400\n",
      "2570/2570 [==============================] - 0s 171us/sample - loss: 0.3871 - accuracy: 0.8206 - val_loss: 0.5040 - val_accuracy: 0.7994\n",
      "Epoch 58/400\n",
      "2570/2570 [==============================] - 0s 161us/sample - loss: 0.3965 - accuracy: 0.8171 - val_loss: 0.4352 - val_accuracy: 0.8398\n",
      "Epoch 59/400\n",
      "2570/2570 [==============================] - 0s 190us/sample - loss: 0.3776 - accuracy: 0.8265 - val_loss: 0.6432 - val_accuracy: 0.7309\n",
      "Epoch 60/400\n",
      "2570/2570 [==============================] - 0s 171us/sample - loss: 0.3726 - accuracy: 0.8354 - val_loss: 0.5511 - val_accuracy: 0.7745\n",
      "Epoch 61/400\n",
      "2570/2570 [==============================] - 0s 189us/sample - loss: 0.3806 - accuracy: 0.8284 - val_loss: 0.4144 - val_accuracy: 0.8538\n",
      "Epoch 62/400\n",
      "2570/2570 [==============================] - 0s 171us/sample - loss: 0.3800 - accuracy: 0.8214 - val_loss: 0.3862 - val_accuracy: 0.8647\n",
      "Epoch 63/400\n",
      "2570/2570 [==============================] - 0s 170us/sample - loss: 0.3796 - accuracy: 0.8171 - val_loss: 0.5387 - val_accuracy: 0.7838\n",
      "Epoch 64/400\n",
      "2570/2570 [==============================] - 0s 171us/sample - loss: 0.3894 - accuracy: 0.8144 - val_loss: 0.4528 - val_accuracy: 0.8305\n",
      "Epoch 65/400\n",
      "2570/2570 [==============================] - 1s 201us/sample - loss: 0.3757 - accuracy: 0.8268 - val_loss: 0.3326 - val_accuracy: 0.8834\n",
      "Epoch 66/400\n",
      "2570/2570 [==============================] - 1s 204us/sample - loss: 0.3868 - accuracy: 0.8191 - val_loss: 0.3734 - val_accuracy: 0.8600\n",
      "Epoch 67/400\n",
      "2570/2570 [==============================] - 1s 199us/sample - loss: 0.3692 - accuracy: 0.8374 - val_loss: 0.6646 - val_accuracy: 0.7170\n",
      "Epoch 68/400\n",
      "2570/2570 [==============================] - 0s 192us/sample - loss: 0.3779 - accuracy: 0.8276 - val_loss: 0.2901 - val_accuracy: 0.8958\n",
      "Epoch 69/400\n",
      "2570/2570 [==============================] - 0s 189us/sample - loss: 0.3731 - accuracy: 0.8210 - val_loss: 0.4512 - val_accuracy: 0.8320\n",
      "Epoch 70/400\n",
      "2570/2570 [==============================] - 1s 216us/sample - loss: 0.3859 - accuracy: 0.8284 - val_loss: 0.5439 - val_accuracy: 0.7792\n",
      "Epoch 71/400\n",
      "2570/2570 [==============================] - 1s 232us/sample - loss: 0.3889 - accuracy: 0.8152 - val_loss: 0.4495 - val_accuracy: 0.8258\n",
      "Epoch 72/400\n",
      "2570/2570 [==============================] - 1s 234us/sample - loss: 0.3738 - accuracy: 0.8300 - val_loss: 0.4732 - val_accuracy: 0.8274\n",
      "Epoch 73/400\n",
      "2570/2570 [==============================] - 1s 245us/sample - loss: 0.3842 - accuracy: 0.8218 - val_loss: 0.2590 - val_accuracy: 0.9067\n",
      "Epoch 74/400\n",
      "2570/2570 [==============================] - 1s 231us/sample - loss: 0.3744 - accuracy: 0.8257 - val_loss: 0.5591 - val_accuracy: 0.7807\n",
      "Epoch 75/400\n",
      "2570/2570 [==============================] - 1s 231us/sample - loss: 0.3758 - accuracy: 0.8315 - val_loss: 0.5405 - val_accuracy: 0.7838\n",
      "Epoch 76/400\n",
      "2570/2570 [==============================] - 1s 230us/sample - loss: 0.3743 - accuracy: 0.8327 - val_loss: 0.3962 - val_accuracy: 0.8600\n",
      "Epoch 77/400\n",
      "2570/2570 [==============================] - 2s 733us/sample - loss: 0.3688 - accuracy: 0.8272 - val_loss: 0.3501 - val_accuracy: 0.8694\n",
      "Epoch 78/400\n",
      "2570/2570 [==============================] - 2s 705us/sample - loss: 0.3736 - accuracy: 0.8226 - val_loss: 0.4746 - val_accuracy: 0.8196\n",
      "Epoch 79/400\n",
      "2570/2570 [==============================] - 2s 707us/sample - loss: 0.3770 - accuracy: 0.8253 - val_loss: 0.4509 - val_accuracy: 0.8305\n",
      "Epoch 80/400\n",
      "2570/2570 [==============================] - 2s 709us/sample - loss: 0.3736 - accuracy: 0.8327 - val_loss: 0.4137 - val_accuracy: 0.8507\n",
      "Epoch 81/400\n",
      "2570/2570 [==============================] - 2s 627us/sample - loss: 0.3729 - accuracy: 0.8226 - val_loss: 0.7005 - val_accuracy: 0.6936\n",
      "Epoch 82/400\n",
      "2570/2570 [==============================] - 1s 414us/sample - loss: 0.3701 - accuracy: 0.8296 - val_loss: 0.4488 - val_accuracy: 0.8398\n",
      "Epoch 83/400\n",
      "2570/2570 [==============================] - 1s 300us/sample - loss: 0.3750 - accuracy: 0.8222 - val_loss: 0.5191 - val_accuracy: 0.8009\n",
      "Epoch 84/400\n",
      "2570/2570 [==============================] - 1s 268us/sample - loss: 0.3756 - accuracy: 0.8296 - val_loss: 0.3210 - val_accuracy: 0.8927\n",
      "Epoch 85/400\n",
      "2570/2570 [==============================] - 1s 230us/sample - loss: 0.3761 - accuracy: 0.8377 - val_loss: 0.5611 - val_accuracy: 0.7807\n",
      "Epoch 86/400\n",
      "2570/2570 [==============================] - 0s 193us/sample - loss: 0.3697 - accuracy: 0.8272 - val_loss: 0.4048 - val_accuracy: 0.8600\n",
      "Epoch 87/400\n",
      "2570/2570 [==============================] - 0s 192us/sample - loss: 0.3783 - accuracy: 0.8261 - val_loss: 0.5680 - val_accuracy: 0.7698\n",
      "Epoch 88/400\n",
      "2570/2570 [==============================] - 1s 227us/sample - loss: 0.3765 - accuracy: 0.8268 - val_loss: 0.3441 - val_accuracy: 0.8771\n",
      "Epoch 89/400\n",
      "2570/2570 [==============================] - 1s 229us/sample - loss: 0.3695 - accuracy: 0.8389 - val_loss: 0.3561 - val_accuracy: 0.8725\n",
      "Epoch 90/400\n",
      "2570/2570 [==============================] - 1s 195us/sample - loss: 0.3776 - accuracy: 0.8311 - val_loss: 0.3148 - val_accuracy: 0.8896\n",
      "Epoch 91/400\n",
      "2570/2570 [==============================] - 1s 204us/sample - loss: 0.3705 - accuracy: 0.8319 - val_loss: 0.7016 - val_accuracy: 0.7014\n",
      "Epoch 92/400\n",
      "2570/2570 [==============================] - 1s 232us/sample - loss: 0.3728 - accuracy: 0.8331 - val_loss: 0.8549 - val_accuracy: 0.5645\n",
      "Epoch 93/400\n",
      "2570/2570 [==============================] - 1s 230us/sample - loss: 0.3751 - accuracy: 0.8311 - val_loss: 0.4232 - val_accuracy: 0.8398\n",
      "Epoch 94/400\n",
      "2570/2570 [==============================] - 1s 208us/sample - loss: 0.3775 - accuracy: 0.8296 - val_loss: 0.3820 - val_accuracy: 0.8569\n",
      "Epoch 95/400\n",
      "2570/2570 [==============================] - 0s 170us/sample - loss: 0.3822 - accuracy: 0.8222 - val_loss: 0.2989 - val_accuracy: 0.9005\n",
      "Epoch 96/400\n",
      "2570/2570 [==============================] - 0s 161us/sample - loss: 0.3758 - accuracy: 0.8233 - val_loss: 0.6565 - val_accuracy: 0.7232\n",
      "Epoch 97/400\n",
      "2570/2570 [==============================] - 0s 175us/sample - loss: 0.3754 - accuracy: 0.8284 - val_loss: 0.4969 - val_accuracy: 0.8072\n",
      "Epoch 98/400\n",
      "2570/2570 [==============================] - 1s 197us/sample - loss: 0.3815 - accuracy: 0.8218 - val_loss: 0.4424 - val_accuracy: 0.8398\n",
      "Epoch 99/400\n",
      "2570/2570 [==============================] - 1s 201us/sample - loss: 0.3700 - accuracy: 0.8241 - val_loss: 0.3572 - val_accuracy: 0.8756\n",
      "Epoch 100/400\n",
      "2570/2570 [==============================] - 1s 200us/sample - loss: 0.3757 - accuracy: 0.8315 - val_loss: 0.5051 - val_accuracy: 0.8056\n",
      "Epoch 101/400\n",
      "2570/2570 [==============================] - 0s 186us/sample - loss: 0.3854 - accuracy: 0.8253 - val_loss: 0.3324 - val_accuracy: 0.8849\n",
      "Epoch 102/400\n",
      "2560/2570 [============================>.] - ETA: 0s - loss: 0.3729 - accuracy: 0.8305\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2570/2570 [==============================] - 0s 190us/sample - loss: 0.3726 - accuracy: 0.8307 - val_loss: 0.5045 - val_accuracy: 0.8056\n",
      "Epoch 103/400\n",
      "2570/2570 [==============================] - 0s 186us/sample - loss: 0.3772 - accuracy: 0.8226 - val_loss: 0.4076 - val_accuracy: 0.8491\n",
      "Epoch 104/400\n",
      "2570/2570 [==============================] - 0s 186us/sample - loss: 0.3833 - accuracy: 0.8202 - val_loss: 0.4925 - val_accuracy: 0.8134\n",
      "Epoch 105/400\n",
      "2570/2570 [==============================] - 1s 251us/sample - loss: 0.3788 - accuracy: 0.8226 - val_loss: 0.5168 - val_accuracy: 0.7978\n",
      "Epoch 106/400\n",
      "2570/2570 [==============================] - 1s 290us/sample - loss: 0.3734 - accuracy: 0.8327 - val_loss: 0.4827 - val_accuracy: 0.8118\n",
      "Epoch 107/400\n",
      "2570/2570 [==============================] - 1s 238us/sample - loss: 0.3601 - accuracy: 0.8339 - val_loss: 0.4039 - val_accuracy: 0.8538\n",
      "Epoch 108/400\n",
      "2570/2570 [==============================] - 1s 264us/sample - loss: 0.3666 - accuracy: 0.8370 - val_loss: 0.4368 - val_accuracy: 0.8351\n",
      "Epoch 109/400\n",
      "2570/2570 [==============================] - 1s 290us/sample - loss: 0.3782 - accuracy: 0.8218 - val_loss: 0.5143 - val_accuracy: 0.8009\n",
      "Epoch 110/400\n",
      "2570/2570 [==============================] - 1s 235us/sample - loss: 0.3637 - accuracy: 0.8311 - val_loss: 0.4408 - val_accuracy: 0.8336\n",
      "Epoch 111/400\n",
      "2570/2570 [==============================] - 1s 232us/sample - loss: 0.3658 - accuracy: 0.8319 - val_loss: 0.4751 - val_accuracy: 0.8227\n",
      "Epoch 112/400\n",
      "2570/2570 [==============================] - 1s 195us/sample - loss: 0.3817 - accuracy: 0.8222 - val_loss: 0.4268 - val_accuracy: 0.8460\n",
      "Epoch 113/400\n",
      "2570/2570 [==============================] - 1s 223us/sample - loss: 0.3833 - accuracy: 0.8249 - val_loss: 0.4621 - val_accuracy: 0.8274\n",
      "Epoch 00113: early stopping\n",
      "3213/1 - 0s - loss: 0.2428 - accuracy: 0.8441\n",
      "train_score [0.36438581690892524, 0.844071]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input,Conv1D, Activation, GlobalMaxPooling1D, BatchNormalization, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inp=Input(shape=(16,3))\n",
    "conv=Conv1D(5, 3, use_bias=False, name='conv1')(inp)\n",
    "conv=GlobalMaxPooling1D()(conv)\n",
    "conv = BatchNormalization(momentum=0.8)(conv)\n",
    "\n",
    "conv=Dense(1,use_bias=True, activation='sigmoid')(conv)\n",
    "# conv=Dense(1,use_bias=True)(conv)\n",
    "model=Model(inputs=inp,outputs=conv)\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# filepath=r'/home/sgr/Загрузки/coh_model_simple1.h5'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', mode='min', patience=40, verbose=1)\n",
    "# mcp_save = ModelCheckpoint(filepath, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=25, verbose=1, min_delta=1e-4, mode='min')\n",
    "\n",
    "# model.fit(X, y, batch_size=16, epochs=400, verbose=1, callbacks=[earlyStopping, mcp_save,reduce_lr_loss], validation_split=0.2)\n",
    "\n",
    "model.fit(X, y, batch_size=16, epochs=400, verbose=1, callbacks=[earlyStopping,reduce_lr_loss], validation_split=0.2)\n",
    "print(\"train_score\", model.evaluate(X, y, batch_size=16, verbose=2))\n",
    "\n",
    "# model.load_weights(filepath)\n",
    "\n",
    "\n",
    "# print(\"train_score\", model.evaluate(x_train, y_train, batch_size=16, verbose=2))\n",
    "# print(\"valid_score\", model.evaluate(x_test, y_test, batch_size=16, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'/home/sgr/Загрузки/featured_points_coh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['istarget', 's1_2018'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['s1_2018']=df['s1_2018'].apply(lambda x:(eval(x)))\n",
    "# df['s1_2018']=df['s1_2018'].apply(lambda x:np.array(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "istarget     int64\n",
       "s1_2018     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "arr=df['s1_2018'].values\n",
    "X=np.array([np.array(i) for i in arr])\n",
    "X=np.expand_dims(X,axis=-1)\n",
    "\n",
    "y=df['istarget'].astype(int).values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('my_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30000000000000027"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.2*0.2+0.1*0.5+0.8*0.7)*-2+1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[0.193899  ]],\n",
       " \n",
       "        [[0.10519723]],\n",
       " \n",
       "        [[0.8271459 ]]], dtype=float32),\n",
       " array([[-1.9613078]], dtype=float32),\n",
       " array([1.6342384], dtype=float32)]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[0.193899  ]],\n",
       " \n",
       "        [[0.10519723]],\n",
       " \n",
       "        [[0.8271459 ]]], dtype=float32)]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(name='conv1').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2570 samples, validate on 643 samples\n",
      "Epoch 1/400\n",
      "2570/2570 [==============================] - 1s 388us/sample - loss: 1.2575 - accuracy: 0.7576 - val_loss: 1.8708 - val_accuracy: 0.6703\n",
      "Epoch 2/400\n",
      "2570/2570 [==============================] - 0s 130us/sample - loss: 1.0487 - accuracy: 0.7518 - val_loss: 2.0609 - val_accuracy: 0.5941\n",
      "Epoch 3/400\n",
      "2570/2570 [==============================] - 0s 136us/sample - loss: 0.9023 - accuracy: 0.7537 - val_loss: 1.3621 - val_accuracy: 0.6998\n",
      "Epoch 4/400\n",
      "2570/2570 [==============================] - 0s 140us/sample - loss: 0.8247 - accuracy: 0.7595 - val_loss: 0.9681 - val_accuracy: 0.7325\n",
      "Epoch 5/400\n",
      "2570/2570 [==============================] - 0s 142us/sample - loss: 0.8154 - accuracy: 0.7607 - val_loss: 1.1361 - val_accuracy: 0.7076\n",
      "Epoch 6/400\n",
      "2570/2570 [==============================] - 0s 137us/sample - loss: 0.7394 - accuracy: 0.7634 - val_loss: 1.0494 - val_accuracy: 0.7076\n",
      "Epoch 7/400\n",
      "2570/2570 [==============================] - 0s 144us/sample - loss: 0.6921 - accuracy: 0.7549 - val_loss: 1.0025 - val_accuracy: 0.7434\n",
      "Epoch 8/400\n",
      "2570/2570 [==============================] - 0s 139us/sample - loss: 0.7168 - accuracy: 0.7556 - val_loss: 1.0202 - val_accuracy: 0.7061\n",
      "Epoch 9/400\n",
      "2570/2570 [==============================] - 0s 154us/sample - loss: 0.6416 - accuracy: 0.7638 - val_loss: 0.7656 - val_accuracy: 0.7496\n",
      "Epoch 10/400\n",
      "2570/2570 [==============================] - 0s 147us/sample - loss: 0.6642 - accuracy: 0.7704 - val_loss: 1.0693 - val_accuracy: 0.7045\n",
      "Epoch 11/400\n",
      "2570/2570 [==============================] - 0s 154us/sample - loss: 0.6208 - accuracy: 0.7599 - val_loss: 0.6183 - val_accuracy: 0.8009\n",
      "Epoch 12/400\n",
      "2570/2570 [==============================] - 0s 148us/sample - loss: 0.5639 - accuracy: 0.7576 - val_loss: 0.7616 - val_accuracy: 0.7449\n",
      "Epoch 13/400\n",
      "2570/2570 [==============================] - 0s 150us/sample - loss: 0.5642 - accuracy: 0.7630 - val_loss: 0.7125 - val_accuracy: 0.7434\n",
      "Epoch 14/400\n",
      "2570/2570 [==============================] - 0s 156us/sample - loss: 0.5137 - accuracy: 0.7595 - val_loss: 0.8923 - val_accuracy: 0.7092\n",
      "Epoch 15/400\n",
      "2570/2570 [==============================] - 0s 168us/sample - loss: 0.5300 - accuracy: 0.7619 - val_loss: 0.8291 - val_accuracy: 0.6905\n",
      "Epoch 16/400\n",
      "2570/2570 [==============================] - 0s 165us/sample - loss: 0.5394 - accuracy: 0.7689 - val_loss: 0.7281 - val_accuracy: 0.7341\n",
      "Epoch 17/400\n",
      "2570/2570 [==============================] - 0s 164us/sample - loss: 0.5330 - accuracy: 0.7732 - val_loss: 0.7724 - val_accuracy: 0.7014\n",
      "Epoch 18/400\n",
      "2570/2570 [==============================] - 0s 173us/sample - loss: 0.4974 - accuracy: 0.7634 - val_loss: 0.8395 - val_accuracy: 0.7138\n",
      "Epoch 19/400\n",
      "2570/2570 [==============================] - 0s 173us/sample - loss: 0.4940 - accuracy: 0.7689 - val_loss: 0.9178 - val_accuracy: 0.6672\n",
      "Epoch 20/400\n",
      "2570/2570 [==============================] - 0s 164us/sample - loss: 0.5077 - accuracy: 0.7661 - val_loss: 0.6490 - val_accuracy: 0.7543\n",
      "Epoch 21/400\n",
      "2570/2570 [==============================] - 0s 167us/sample - loss: 0.4900 - accuracy: 0.7654 - val_loss: 0.7171 - val_accuracy: 0.7138\n",
      "Epoch 22/400\n",
      "2570/2570 [==============================] - 0s 178us/sample - loss: 0.5051 - accuracy: 0.7696 - val_loss: 0.7442 - val_accuracy: 0.7076\n",
      "Epoch 23/400\n",
      "2570/2570 [==============================] - 0s 176us/sample - loss: 0.4874 - accuracy: 0.7751 - val_loss: 0.7192 - val_accuracy: 0.7309\n",
      "Epoch 24/400\n",
      "2570/2570 [==============================] - 0s 191us/sample - loss: 0.4853 - accuracy: 0.7767 - val_loss: 0.6995 - val_accuracy: 0.7309\n",
      "Epoch 25/400\n",
      "2570/2570 [==============================] - 0s 191us/sample - loss: 0.4659 - accuracy: 0.7720 - val_loss: 0.9720 - val_accuracy: 0.6221\n",
      "Epoch 26/400\n",
      "2570/2570 [==============================] - 0s 192us/sample - loss: 0.4617 - accuracy: 0.7704 - val_loss: 0.6797 - val_accuracy: 0.7589\n",
      "Epoch 27/400\n",
      "2570/2570 [==============================] - 0s 194us/sample - loss: 0.4845 - accuracy: 0.7708 - val_loss: 0.6708 - val_accuracy: 0.7543\n",
      "Epoch 28/400\n",
      "2570/2570 [==============================] - 0s 193us/sample - loss: 0.4697 - accuracy: 0.7759 - val_loss: 0.5495 - val_accuracy: 0.7994\n",
      "Epoch 29/400\n",
      "2570/2570 [==============================] - 1s 205us/sample - loss: 0.4704 - accuracy: 0.7720 - val_loss: 0.6649 - val_accuracy: 0.7574\n",
      "Epoch 30/400\n",
      "2570/2570 [==============================] - 0s 187us/sample - loss: 0.4694 - accuracy: 0.7767 - val_loss: 0.6867 - val_accuracy: 0.7496\n",
      "Epoch 31/400\n",
      "2570/2570 [==============================] - 1s 196us/sample - loss: 0.4736 - accuracy: 0.7790 - val_loss: 0.7492 - val_accuracy: 0.7232\n",
      "Epoch 32/400\n",
      "2570/2570 [==============================] - 1s 198us/sample - loss: 0.4606 - accuracy: 0.7825 - val_loss: 0.7546 - val_accuracy: 0.7107\n",
      "Epoch 33/400\n",
      "2570/2570 [==============================] - 1s 209us/sample - loss: 0.4656 - accuracy: 0.7856 - val_loss: 0.7429 - val_accuracy: 0.7138\n",
      "Epoch 34/400\n",
      "2570/2570 [==============================] - 1s 200us/sample - loss: 0.4903 - accuracy: 0.7774 - val_loss: 0.6813 - val_accuracy: 0.7652\n",
      "Epoch 35/400\n",
      "2570/2570 [==============================] - 1s 199us/sample - loss: 0.4626 - accuracy: 0.7782 - val_loss: 0.7145 - val_accuracy: 0.7403\n",
      "Epoch 36/400\n",
      "2570/2570 [==============================] - 0s 187us/sample - loss: 0.4626 - accuracy: 0.7794 - val_loss: 0.6465 - val_accuracy: 0.7683\n",
      "Epoch 37/400\n",
      "2570/2570 [==============================] - 1s 206us/sample - loss: 0.4922 - accuracy: 0.7704 - val_loss: 0.8914 - val_accuracy: 0.6703\n",
      "Epoch 38/400\n",
      "2570/2570 [==============================] - 1s 204us/sample - loss: 0.4777 - accuracy: 0.7763 - val_loss: 0.7391 - val_accuracy: 0.7325\n",
      "Epoch 39/400\n",
      "2570/2570 [==============================] - 0s 188us/sample - loss: 0.4665 - accuracy: 0.7751 - val_loss: 0.8333 - val_accuracy: 0.6874\n",
      "Epoch 40/400\n",
      "2570/2570 [==============================] - 1s 198us/sample - loss: 0.5013 - accuracy: 0.7735 - val_loss: 0.8347 - val_accuracy: 0.6998\n",
      "Epoch 41/400\n",
      "2570/2570 [==============================] - 0s 192us/sample - loss: 0.4951 - accuracy: 0.7856 - val_loss: 0.8210 - val_accuracy: 0.6967\n",
      "Epoch 42/400\n",
      "2570/2570 [==============================] - 1s 196us/sample - loss: 0.4696 - accuracy: 0.7763 - val_loss: 0.7516 - val_accuracy: 0.7247\n",
      "Epoch 43/400\n",
      "2570/2570 [==============================] - 0s 187us/sample - loss: 0.4840 - accuracy: 0.7782 - val_loss: 0.8344 - val_accuracy: 0.7030\n",
      "Epoch 44/400\n",
      "2570/2570 [==============================] - 1s 233us/sample - loss: 0.4653 - accuracy: 0.7833 - val_loss: 0.5797 - val_accuracy: 0.7854\n",
      "Epoch 45/400\n",
      "2570/2570 [==============================] - 1s 206us/sample - loss: 0.4775 - accuracy: 0.7634 - val_loss: 0.7213 - val_accuracy: 0.6998\n",
      "Epoch 46/400\n",
      "2570/2570 [==============================] - 1s 217us/sample - loss: 0.4612 - accuracy: 0.7677 - val_loss: 0.6838 - val_accuracy: 0.7278\n",
      "Epoch 47/400\n",
      "2570/2570 [==============================] - 1s 225us/sample - loss: 0.4614 - accuracy: 0.7724 - val_loss: 0.6090 - val_accuracy: 0.7589\n",
      "Epoch 48/400\n",
      "2570/2570 [==============================] - 0s 185us/sample - loss: 0.4688 - accuracy: 0.7833 - val_loss: 0.6142 - val_accuracy: 0.7574\n",
      "Epoch 49/400\n",
      "2570/2570 [==============================] - 1s 214us/sample - loss: 0.4657 - accuracy: 0.7821 - val_loss: 0.6747 - val_accuracy: 0.7496\n",
      "Epoch 50/400\n",
      "2570/2570 [==============================] - 1s 212us/sample - loss: 0.4660 - accuracy: 0.7732 - val_loss: 0.8082 - val_accuracy: 0.6921\n",
      "Epoch 51/400\n",
      "2570/2570 [==============================] - 1s 205us/sample - loss: 0.4772 - accuracy: 0.7743 - val_loss: 0.6334 - val_accuracy: 0.7496\n",
      "Epoch 52/400\n",
      "2570/2570 [==============================] - 1s 209us/sample - loss: 0.4586 - accuracy: 0.7732 - val_loss: 0.7936 - val_accuracy: 0.7154\n",
      "Epoch 53/400\n",
      "2570/2570 [==============================] - 1s 210us/sample - loss: 0.4733 - accuracy: 0.7755 - val_loss: 0.7113 - val_accuracy: 0.7154\n",
      "Epoch 54/400\n",
      "2570/2570 [==============================] - 1s 196us/sample - loss: 0.4522 - accuracy: 0.7833 - val_loss: 0.8362 - val_accuracy: 0.6827\n",
      "Epoch 55/400\n",
      "2570/2570 [==============================] - 1s 228us/sample - loss: 0.4680 - accuracy: 0.7739 - val_loss: 0.7843 - val_accuracy: 0.7092\n",
      "Epoch 56/400\n",
      "2570/2570 [==============================] - 1s 221us/sample - loss: 0.4701 - accuracy: 0.7786 - val_loss: 0.6397 - val_accuracy: 0.7714\n",
      "Epoch 57/400\n",
      "2570/2570 [==============================] - 1s 212us/sample - loss: 0.4647 - accuracy: 0.7704 - val_loss: 0.5626 - val_accuracy: 0.7978\n",
      "Epoch 58/400\n",
      "2570/2570 [==============================] - 1s 234us/sample - loss: 0.4573 - accuracy: 0.7774 - val_loss: 0.7120 - val_accuracy: 0.7092\n",
      "Epoch 59/400\n",
      "2570/2570 [==============================] - 1s 248us/sample - loss: 0.4594 - accuracy: 0.7786 - val_loss: 0.8265 - val_accuracy: 0.6998\n",
      "Epoch 60/400\n",
      "2570/2570 [==============================] - 1s 251us/sample - loss: 0.4709 - accuracy: 0.7798 - val_loss: 0.8126 - val_accuracy: 0.7092\n",
      "Epoch 61/400\n",
      "2570/2570 [==============================] - 1s 233us/sample - loss: 0.4650 - accuracy: 0.7763 - val_loss: 0.6999 - val_accuracy: 0.7278\n",
      "Epoch 62/400\n",
      "2570/2570 [==============================] - 1s 238us/sample - loss: 0.4555 - accuracy: 0.7790 - val_loss: 0.8185 - val_accuracy: 0.7045\n",
      "Epoch 63/400\n",
      "2570/2570 [==============================] - 1s 237us/sample - loss: 0.4797 - accuracy: 0.7700 - val_loss: 0.7017 - val_accuracy: 0.7278\n",
      "Epoch 64/400\n",
      "2570/2570 [==============================] - 1s 420us/sample - loss: 0.4630 - accuracy: 0.7732 - val_loss: 0.7019 - val_accuracy: 0.7434\n",
      "Epoch 65/400\n",
      "2570/2570 [==============================] - 2s 735us/sample - loss: 0.4637 - accuracy: 0.7739 - val_loss: 0.6817 - val_accuracy: 0.7387\n",
      "Epoch 66/400\n",
      "2570/2570 [==============================] - 2s 711us/sample - loss: 0.4657 - accuracy: 0.7786 - val_loss: 0.8829 - val_accuracy: 0.6874\n",
      "Epoch 67/400\n",
      "2570/2570 [==============================] - 2s 747us/sample - loss: 0.4580 - accuracy: 0.7720 - val_loss: 0.5640 - val_accuracy: 0.7978\n",
      "Epoch 68/400\n",
      "2570/2570 [==============================] - 2s 751us/sample - loss: 0.4659 - accuracy: 0.7743 - val_loss: 0.8163 - val_accuracy: 0.7045\n",
      "Epoch 00068: early stopping\n",
      "2570/1 - 1s - loss: 0.4384 - accuracy: 0.7669\n",
      "train_score [0.5238980974436734, 0.76692605]\n",
      "643/1 - 0s - loss: 0.3308 - accuracy: 0.7823\n",
      "valid_score [0.4766652404010574, 0.7822706]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input,Conv1D, Activation, GlobalMaxPooling1D, BatchNormalization, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inp=Input(shape=(16,1))\n",
    "conv=Conv1D(1, 3, use_bias=False, name='conv1')(inp)\n",
    "conv=GlobalMaxPooling1D()(conv)\n",
    "conv = BatchNormalization(momentum=0.8)(conv)\n",
    "# conv=Activation('sigmoid')(conv)\n",
    "# conv=Dense(1,use_bias=True, activation='sigmoid')(conv)\n",
    "conv=Dense(1,use_bias=True)(conv)\n",
    "model=Model(inputs=inp,outputs=conv)\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "filepath=r'/home/sgr/Загрузки/coh_model_simple1.h5'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', mode='min', patience=40, verbose=1)\n",
    "mcp_save = ModelCheckpoint(filepath, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=25, verbose=1, min_delta=1e-4, mode='min')\n",
    "\n",
    "model.fit(X, y, batch_size=16, epochs=400, verbose=1, callbacks=[earlyStopping, mcp_save,reduce_lr_loss], validation_split=0.2)\n",
    "\n",
    "# model.fit(X, y, batch_size=16, epochs=400, verbose=1, callbacks=[mcp_save,reduce_lr_loss], validation_split=0.2)\n",
    "\n",
    "# model.load_weights(filepath)\n",
    "\n",
    "\n",
    "print(\"train_score\", model.evaluate(x_train, y_train, batch_size=16, verbose=2))\n",
    "print(\"valid_score\", model.evaluate(x_test, y_test, batch_size=16, verbose=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3213/1 - 1s - loss: 0.3997 - accuracy: 0.7700\n",
      "train_score [0.514445650319685, 0.7699969]\n"
     ]
    }
   ],
   "source": [
    "print(\"train_score\", model.evaluate(X, y, batch_size=16, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "one_ind=np.random.choice(np.where(y==1)[0])\n",
    "zero_ind=np.random.choice(np.where(y==0)[0])\n",
    "\n",
    "for num, (line_id, name) in enumerate(zip([one_ind, zero_ind],['one','using'])):\n",
    "    plt.subplot(1,2,num+1)\n",
    "    plt.bar(np.arange(16),X[line_id][:,0])\n",
    "    plt.title(f'{name} {y[line_id]}/{y_pred[line_id][0]:.2f}')\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23055188]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=np.full([16,1], 0.2)\n",
    "# test[-1]=0.6\n",
    "test[-1]=0.7\n",
    "model.predict(test[None,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(bin_arr):\n",
    "    ln=bin_arr.shape[0]\n",
    "    ones=np.sum(bin_arr.flatten())\n",
    "    zeros=ln-ones\n",
    "    if ones*zeros==0:return 0\n",
    "    return -ones/ln*np.log2(ones/ln)-zeros/ln*np.log2(zeros/ln)\n",
    "\n",
    "def conv1d(arr, kernel):    \n",
    "    arr=arr.flatten()\n",
    "    kernel=kernel.flatten()\n",
    "    lenn=kernel.shape[0]    \n",
    "    arlen=arr.shape[0]\n",
    "    outt=[]\n",
    "    for i in range(lenn):\n",
    "        outt.append(arr[i:arlen-(lenn-i-1)])\n",
    "    return np.array(outt).T.dot(kernel)\n",
    "batch_conv1d = np.vectorize(conv1d, signature='(n,m),(k)->(l)')\n",
    "\n",
    "correlate = np.vectorize(np.correlate, signature='(n),(m)->(k)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=np.random.rand(20,16,1)\n",
    "test_y=np.random.randint(0,2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 16, 1), (20,))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape,test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3213, 16, 1), (3213,))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.00000000e+00, -9.00000000e-01, -8.00000000e-01, -7.00000000e-01,\n",
       "       -6.00000000e-01, -5.00000000e-01, -4.00000000e-01, -3.00000000e-01,\n",
       "       -2.00000000e-01, -1.00000000e-01, -2.22044605e-16,  1.00000000e-01,\n",
       "        2.00000000e-01,  3.00000000e-01,  4.00000000e-01,  5.00000000e-01,\n",
       "        6.00000000e-01,  7.00000000e-01,  8.00000000e-01,  9.00000000e-01,\n",
       "        1.00000000e+00])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(-1,1.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "best=0\n",
    "params={}\n",
    "\n",
    "\n",
    "X_tr=np.random.rand(3000,16,1)\n",
    "y_tr=np.random.randint(0,2,3000)\n",
    "\n",
    "for i in np.arange(-1,1.1,0.1):\n",
    "    for j in np.arange(-1,1.1,0.1):\n",
    "#         for ij in np.arange(-1,1.1,0.1):\n",
    "\n",
    "#         kernel=[-0.4,0.6]\n",
    "        kernel=[i,j]\n",
    "        conved=batch_conv1d(X_tr, kernel)\n",
    "        maxx=conved.max(axis=1)\n",
    "        maxx[np.argsort(conved)]\n",
    "\n",
    "        sorted_y=y_tr[np.argsort(maxx)]\n",
    "        sorted_feat=np.sort(maxx)\n",
    "\n",
    "        beg_entr=entropy(sorted_y)\n",
    "        cut_val=0\n",
    "\n",
    "        cut_ind=0\n",
    "\n",
    "        arr_len=sorted_y.shape[0]\n",
    "        for ind in range(1, sorted_y.shape[0]):\n",
    "            if sorted_y[ind]==sorted_y[ind-1]: continue\n",
    "            left= sorted_y[:ind]  \n",
    "            right= sorted_y[ind:]\n",
    "            l_ent=entropy(left)\n",
    "            r_ent=entropy(right)    \n",
    "            cur_entr= (ind-1)/arr_len*l_ent+(arr_len-ind-1)/arr_len*r_ent                \n",
    "\n",
    "            if cur_entr< beg_entr:\n",
    "                beg_entr=cur_entr\n",
    "                cut_val=(sorted_feat[ind-1]+sorted_feat[ind])/2\n",
    "                cut_ind=ind\n",
    "        compare_arr=np.zeros(arr_len)\n",
    "        compare_arr[:cut_ind]=1\n",
    "        asses=np.sum(compare_arr==sorted_y)/arr_len\n",
    "        if asses>best:\n",
    "            best=asses\n",
    "            params['cut_val']=cut_val\n",
    "            params['cut_ind']=cut_ind \n",
    "            params['beg_entr']=beg_entr\n",
    "            params['kernel']=kernel\n",
    "\n",
    "#         np.sum(compare_arr==sorted_y)/arr_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cut_val': 0.02563241338200064,\n",
       "  'cut_ind': 1740,\n",
       "  'beg_entr': 0.995278216939246,\n",
       "  'kernel': [0.09999999999999964, -0.8]},\n",
       " 0.5373333333333333)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7952069716775599"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7285044293903075, 0.15931941221964424)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(sorted_y[:cut_ind])/cut_ind, np.sum(sorted_y[cut_ind:])/(arr_len-cut_ind-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33715315, 0.3726555 , 0.3818512 , 0.41187758, 0.42491575,\n",
       "       0.43830487, 0.44651313, 0.44728139, 0.4492165 , 0.45072506,\n",
       "       0.45315965, 0.47120151, 0.48562152, 0.48633297, 0.48824995,\n",
       "       0.50583116, 0.50998889, 0.54502015, 0.56594494, 0.5768519 ])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5079100249999999"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.50583116+0.50998889)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 15)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conved.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 15)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_conv1d(test_X, [0.2,0.5]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194 µs ± 5.47 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "batch_conv1d(test_X, [0.2,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 µs ± 3.66 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "correlate(test_X[:,:,0],[0.2,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2570 samples, validate on 643 samples\n",
      "Epoch 1/400\n",
      "2570/2570 [==============================] - 1s 338us/sample - loss: 0.6124 - accuracy: 0.6393 - val_loss: 0.6411 - val_accuracy: 0.8087\n",
      "Epoch 2/400\n",
      "2570/2570 [==============================] - 0s 156us/sample - loss: 0.4742 - accuracy: 0.7700 - val_loss: 0.7239 - val_accuracy: 0.7030\n",
      "Epoch 3/400\n",
      "2570/2570 [==============================] - 0s 179us/sample - loss: 0.4452 - accuracy: 0.7774 - val_loss: 0.7410 - val_accuracy: 0.6703\n",
      "Epoch 4/400\n",
      "2570/2570 [==============================] - 1s 195us/sample - loss: 0.4377 - accuracy: 0.7840 - val_loss: 0.6963 - val_accuracy: 0.7061\n",
      "Epoch 5/400\n",
      "2570/2570 [==============================] - 1s 208us/sample - loss: 0.4287 - accuracy: 0.7899 - val_loss: 0.6068 - val_accuracy: 0.7714\n",
      "Epoch 6/400\n",
      "2570/2570 [==============================] - 1s 241us/sample - loss: 0.4332 - accuracy: 0.7903 - val_loss: 0.5196 - val_accuracy: 0.8149\n",
      "Epoch 7/400\n",
      "2570/2570 [==============================] - 0s 149us/sample - loss: 0.4251 - accuracy: 0.7969 - val_loss: 0.5837 - val_accuracy: 0.7947\n",
      "Epoch 8/400\n",
      "2570/2570 [==============================] - 0s 151us/sample - loss: 0.4183 - accuracy: 0.7973 - val_loss: 0.5731 - val_accuracy: 0.7994\n",
      "Epoch 9/400\n",
      "2570/2570 [==============================] - 0s 186us/sample - loss: 0.4182 - accuracy: 0.7977 - val_loss: 0.6756 - val_accuracy: 0.7387\n",
      "Epoch 10/400\n",
      "2570/2570 [==============================] - 0s 185us/sample - loss: 0.4129 - accuracy: 0.7977 - val_loss: 0.5764 - val_accuracy: 0.8009\n",
      "Epoch 11/400\n",
      "2570/2570 [==============================] - 0s 186us/sample - loss: 0.4154 - accuracy: 0.8000 - val_loss: 0.5891 - val_accuracy: 0.7932\n",
      "Epoch 12/400\n",
      "2570/2570 [==============================] - 1s 205us/sample - loss: 0.4088 - accuracy: 0.8082 - val_loss: 0.5967 - val_accuracy: 0.7900\n",
      "Epoch 13/400\n",
      "2570/2570 [==============================] - 1s 205us/sample - loss: 0.4122 - accuracy: 0.7973 - val_loss: 0.7438 - val_accuracy: 0.7372\n",
      "Epoch 14/400\n",
      "2570/2570 [==============================] - 1s 218us/sample - loss: 0.4106 - accuracy: 0.8019 - val_loss: 0.6766 - val_accuracy: 0.7512\n",
      "Epoch 15/400\n",
      "2570/2570 [==============================] - 1s 209us/sample - loss: 0.4077 - accuracy: 0.8089 - val_loss: 0.5171 - val_accuracy: 0.8149\n",
      "Epoch 16/400\n",
      "2570/2570 [==============================] - 0s 194us/sample - loss: 0.4063 - accuracy: 0.8047 - val_loss: 0.6051 - val_accuracy: 0.7714\n",
      "Epoch 17/400\n",
      "2570/2570 [==============================] - 0s 178us/sample - loss: 0.4097 - accuracy: 0.7984 - val_loss: 0.8159 - val_accuracy: 0.6874\n",
      "Epoch 18/400\n",
      "2570/2570 [==============================] - 0s 184us/sample - loss: 0.4039 - accuracy: 0.8031 - val_loss: 0.6274 - val_accuracy: 0.7776\n",
      "Epoch 19/400\n",
      "2570/2570 [==============================] - 0s 173us/sample - loss: 0.4037 - accuracy: 0.8051 - val_loss: 0.6796 - val_accuracy: 0.7465\n",
      "Epoch 20/400\n",
      "2570/2570 [==============================] - 0s 181us/sample - loss: 0.4003 - accuracy: 0.8132 - val_loss: 0.4665 - val_accuracy: 0.8351\n",
      "Epoch 21/400\n",
      "2570/2570 [==============================] - 0s 150us/sample - loss: 0.4003 - accuracy: 0.8082 - val_loss: 0.7153 - val_accuracy: 0.7107\n",
      "Epoch 22/400\n",
      "2570/2570 [==============================] - 0s 159us/sample - loss: 0.4053 - accuracy: 0.8093 - val_loss: 0.6075 - val_accuracy: 0.7807\n",
      "Epoch 23/400\n",
      "2570/2570 [==============================] - 0s 178us/sample - loss: 0.3929 - accuracy: 0.8121 - val_loss: 0.6917 - val_accuracy: 0.7387\n",
      "Epoch 24/400\n",
      "2570/2570 [==============================] - 0s 170us/sample - loss: 0.3957 - accuracy: 0.8144 - val_loss: 0.6122 - val_accuracy: 0.7698\n",
      "Epoch 25/400\n",
      "2570/2570 [==============================] - 0s 168us/sample - loss: 0.3924 - accuracy: 0.8144 - val_loss: 0.6519 - val_accuracy: 0.7698\n",
      "Epoch 26/400\n",
      "2570/2570 [==============================] - 0s 171us/sample - loss: 0.3878 - accuracy: 0.8062 - val_loss: 0.6365 - val_accuracy: 0.7527\n",
      "Epoch 27/400\n",
      "2570/2570 [==============================] - 1s 205us/sample - loss: 0.3896 - accuracy: 0.8152 - val_loss: 0.4790 - val_accuracy: 0.8460\n",
      "Epoch 28/400\n",
      "2570/2570 [==============================] - 0s 184us/sample - loss: 0.3861 - accuracy: 0.8175 - val_loss: 0.8125 - val_accuracy: 0.6952\n",
      "Epoch 29/400\n",
      "2570/2570 [==============================] - 0s 172us/sample - loss: 0.3899 - accuracy: 0.8160 - val_loss: 0.7515 - val_accuracy: 0.7216\n",
      "Epoch 30/400\n",
      "2570/2570 [==============================] - 0s 178us/sample - loss: 0.3865 - accuracy: 0.8148 - val_loss: 0.5231 - val_accuracy: 0.8274\n",
      "Epoch 31/400\n",
      "2570/2570 [==============================] - 0s 185us/sample - loss: 0.3865 - accuracy: 0.8156 - val_loss: 0.5330 - val_accuracy: 0.8212\n",
      "Epoch 32/400\n",
      "2570/2570 [==============================] - 1s 198us/sample - loss: 0.3842 - accuracy: 0.8152 - val_loss: 0.7922 - val_accuracy: 0.7061\n",
      "Epoch 33/400\n",
      "2570/2570 [==============================] - 1s 208us/sample - loss: 0.3810 - accuracy: 0.8218 - val_loss: 0.7981 - val_accuracy: 0.7092\n",
      "Epoch 34/400\n",
      "2570/2570 [==============================] - 1s 214us/sample - loss: 0.3763 - accuracy: 0.8280 - val_loss: 0.6973 - val_accuracy: 0.7449\n",
      "Epoch 35/400\n",
      "2570/2570 [==============================] - 0s 187us/sample - loss: 0.3766 - accuracy: 0.8222 - val_loss: 0.6283 - val_accuracy: 0.7558\n",
      "Epoch 36/400\n",
      "2570/2570 [==============================] - 0s 189us/sample - loss: 0.3738 - accuracy: 0.8268 - val_loss: 0.6198 - val_accuracy: 0.7807\n",
      "Epoch 37/400\n",
      "2570/2570 [==============================] - 1s 206us/sample - loss: 0.3779 - accuracy: 0.8202 - val_loss: 0.6180 - val_accuracy: 0.7760\n",
      "Epoch 38/400\n",
      "2570/2570 [==============================] - 1s 201us/sample - loss: 0.3733 - accuracy: 0.8288 - val_loss: 0.5472 - val_accuracy: 0.8072\n",
      "Epoch 39/400\n",
      "2570/2570 [==============================] - 1s 209us/sample - loss: 0.3712 - accuracy: 0.8304 - val_loss: 0.7145 - val_accuracy: 0.7418\n",
      "Epoch 40/400\n",
      "2570/2570 [==============================] - 1s 210us/sample - loss: 0.3717 - accuracy: 0.8214 - val_loss: 0.7406 - val_accuracy: 0.7138\n",
      "Epoch 00040: early stopping\n",
      "2570/1 - 0s - loss: 0.4303 - accuracy: 0.8109\n",
      "train_score [0.41867522933603724, 0.81089497]\n",
      "643/1 - 0s - loss: 0.2662 - accuracy: 0.8134\n",
      "valid_score [0.3999227268467795, 0.8133748]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# inp=Input(input_shape=(16,1))\n",
    "\n",
    "model.add(Conv1D(40, 2, activation='relu', input_shape=(16,1)))\n",
    "model.add(Conv1D(40, 2, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(80, 3, activation='relu'))\n",
    "model.add(Conv1D(160, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam')\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "filepath=r'/home/sgr/Загрузки/coh_model1.h5'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1)\n",
    "mcp_save = ModelCheckpoint(filepath, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=15, verbose=1, min_delta=1e-4, mode='min')\n",
    "\n",
    "model.fit(X, y, batch_size=16, epochs=400, verbose=1, callbacks=[earlyStopping, mcp_save,reduce_lr_loss], validation_split=0.2)\n",
    "\n",
    "\n",
    "# model.fit(x_train, y_train, batch_size=16, epochs=80)\n",
    "model.load_weights(filepath)\n",
    "print(\"train_score\", model.evaluate(x_train, y_train, batch_size=16, verbose=2))\n",
    "print(\"valid_score\", model.evaluate(x_test, y_test, batch_size=16, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "# del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv1d_245_input_1:0' shape=(None, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.6176 - acc: 0.6470\n",
      "Epoch 2/40\n",
      "3569/3569 [==============================] - 2s 458us/step - loss: 0.4623 - acc: 0.7795\n",
      "Epoch 3/40\n",
      "3569/3569 [==============================] - 2s 486us/step - loss: 0.4118 - acc: 0.8100\n",
      "Epoch 4/40\n",
      "3569/3569 [==============================] - 3s 830us/step - loss: 0.4009 - acc: 0.8187\n",
      "Epoch 5/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.3837 - acc: 0.8299\n",
      "Epoch 6/40\n",
      "3569/3569 [==============================] - 5s 2ms/step - loss: 0.3751 - acc: 0.8282\n",
      "Epoch 7/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.3532 - acc: 0.8451\n",
      "Epoch 8/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.3544 - acc: 0.8434\n",
      "Epoch 9/40\n",
      "3569/3569 [==============================] - 8s 2ms/step - loss: 0.3385 - acc: 0.8551\n",
      "Epoch 10/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.3305 - acc: 0.8565\n",
      "Epoch 11/40\n",
      "3569/3569 [==============================] - 5s 2ms/step - loss: 0.3229 - acc: 0.8557\n",
      "Epoch 12/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.3096 - acc: 0.8720\n",
      "Epoch 13/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.3084 - acc: 0.8672\n",
      "Epoch 14/40\n",
      "3569/3569 [==============================] - 4s 989us/step - loss: 0.2940 - acc: 0.8795\n",
      "Epoch 15/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.2742 - acc: 0.8857\n",
      "Epoch 16/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.2732 - acc: 0.8902\n",
      "Epoch 17/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.2622 - acc: 0.8893\n",
      "Epoch 18/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.2607 - acc: 0.8907\n",
      "Epoch 19/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.2527 - acc: 0.9019\n",
      "Epoch 20/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.2482 - acc: 0.8991\n",
      "Epoch 21/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.2375 - acc: 0.9031\n",
      "Epoch 22/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.2308 - acc: 0.9078\n",
      "Epoch 23/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.2286 - acc: 0.9148\n",
      "Epoch 24/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.2119 - acc: 0.9140\n",
      "Epoch 25/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.2070 - acc: 0.9171\n",
      "Epoch 26/40\n",
      "3569/3569 [==============================] - 4s 995us/step - loss: 0.2041 - acc: 0.9190\n",
      "Epoch 27/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.1853 - acc: 0.9257\n",
      "Epoch 28/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.1892 - acc: 0.9252\n",
      "Epoch 29/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.1850 - acc: 0.9325\n",
      "Epoch 30/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.1797 - acc: 0.9328\n",
      "Epoch 31/40\n",
      "3569/3569 [==============================] - 5s 2ms/step - loss: 0.1780 - acc: 0.9302\n",
      "Epoch 32/40\n",
      "3569/3569 [==============================] - 3s 972us/step - loss: 0.1848 - acc: 0.9274\n",
      "Epoch 33/40\n",
      "3569/3569 [==============================] - 7s 2ms/step - loss: 0.1795 - acc: 0.9350\n",
      "Epoch 34/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.1653 - acc: 0.9358\n",
      "Epoch 35/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.1600 - acc: 0.9417\n",
      "Epoch 36/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.1517 - acc: 0.9395\n",
      "Epoch 37/40\n",
      "3569/3569 [==============================] - 4s 1ms/step - loss: 0.1590 - acc: 0.9414\n",
      "Epoch 38/40\n",
      "3569/3569 [==============================] - 5s 1ms/step - loss: 0.1519 - acc: 0.9426\n",
      "Epoch 39/40\n",
      "3569/3569 [==============================] - 3s 913us/step - loss: 0.1587 - acc: 0.9456\n",
      "Epoch 40/40\n",
      "3569/3569 [==============================] - 6s 2ms/step - loss: 0.1476 - acc: 0.9445\n",
      "893/893 [==============================] - 1s 1ms/step\n",
      "3569/3569 [==============================] - 1s 214us/step\n",
      "train_score [0.08684802611490765, 0.9731017091622303]\n",
      "valid_score [0.3272134645655334, 0.8992161254866793]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "arr=gg[['vv','vh']].values\n",
    "ii=np.array([np.array([i[0],i[1]]) for i in arr])\n",
    "X=np.swapaxes(ii, 1, 2)\n",
    "\n",
    "#trim 2 first vals for vv, vh\n",
    "X=X[:,2:,:]\n",
    "\n",
    "\n",
    "y=gg['cl'].astype(int).values\n",
    "y=np.reshape(y,(y.size,1))\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(40, 2, activation='relu', input_shape=(15, 2)))\n",
    "model.add(Conv1D(40, 2, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(80, 3, activation='relu'))\n",
    "model.add(Conv1D(160, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=40)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)\n",
    "print(\"train_score\", model.evaluate(x_train, y_train, batch_size=16))\n",
    "print(\"valid_score\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(r\"/home/sgr/Загрузки/SXuynia/model/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(r\"/home/sgr/Загрузки/SXuynia/model/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction on tf record dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/arrsent1_2019-00000.tfrecord.gz', 'data/arrsent1_2019-00001.tfrecord.gz', 'data/arrsent1_2019-00002.tfrecord.gz', 'data/arrsent1_2019-00003.tfrecord.gz', 'data/arrsent1_2019-00004.tfrecord.gz', 'data/arrsent1_2019-00005.tfrecord.gz', 'data/arrsent1_2019-00006.tfrecord.gz', 'data/arrsent1_2019-00007.tfrecord.gz', 'data/arrsent1_2019-00008.tfrecord.gz', 'data/arrsent1_2019-00009.tfrecord.gz', 'data/arrsent1_2019-00010.tfrecord.gz', 'data/arrsent1_2019-00011.tfrecord.gz', 'data/arrsent1_2019-00012.tfrecord.gz', 'data/arrsent1_2019-00013.tfrecord.gz', 'data/arrsent1_2019-00014.tfrecord.gz', 'data/arrsent1_2019-00015.tfrecord.gz', 'data/arrsent1_2019-00016.tfrecord.gz', 'data/arrsent1_2019-00017.tfrecord.gz', 'data/arrsent1_2019-00018.tfrecord.gz', 'data/arrsent1_2019-00019.tfrecord.gz', 'data/arrsent1_2019-00020.tfrecord.gz', 'data/arrsent1_2019-00021.tfrecord.gz']\n",
      "data/arrsent1_2019-mixer.json\n",
      "{'projection': {'crs': 'EPSG:32635', 'affine': {'doubleMatrix': [20.0, 0.0, 567680.0, 0.0, -20.0, 6223500.0]}}, 'patchDimensions': [256, 256], 'patchesPerRow': 19, 'totalPatches': 513}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# json_file1='data/arrsent1_2018-mixer.json'\n",
    "OUTPUT_BUCKET='data'\n",
    "IMAGE_FILE_PREFIX='arrsent1_2019'\n",
    "\n",
    "# Get a list of all the files in the output bucket.\n",
    "files_list = !ls {OUTPUT_BUCKET}\n",
    "# Get only the files generated by the image export.\n",
    "exported_files_list = [s for s in files_list if IMAGE_FILE_PREFIX in s]\n",
    "\n",
    "# Get the list of image files and the JSON mixer file.\n",
    "image_files_list = []\n",
    "json_file = None\n",
    "for f in exported_files_list:\n",
    "    if f.endswith('.tfrecord.gz'):\n",
    "        image_files_list.append(\"{0}/{1}\".format(OUTPUT_BUCKET,f))\n",
    "    elif f.endswith('.json'):\n",
    "        json_file = \"{0}/{1}\".format(OUTPUT_BUCKET,f)\n",
    "\n",
    "# Make sure the files are in the right order.\n",
    "image_files_list.sort()\n",
    "\n",
    "print(image_files_list)\n",
    "print(json_file)\n",
    "\n",
    "# Load the contents of the mixer file to a JSON object.\n",
    "json_text = !cat {json_file}\n",
    "# Get a single string w/ newlines from the IPython.utils.text.SList\n",
    "mixer = json.loads(json_text.nlstr)\n",
    "print(mixer)\n",
    "# print(json_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS=['s1_2019']\n",
    "\n",
    "patch_width = mixer['patchDimensions'][0]\n",
    "patch_height = mixer['patchDimensions'][1]\n",
    "patches = mixer['totalPatches']\n",
    "\n",
    "patch_dimensions_flat = [16,patch_width * patch_height]\n",
    "\n",
    "cols=mixer['patchesPerRow']\n",
    "rows=int(patches/cols)\n",
    "\n",
    "image_columns = [tf.io.FixedLenFeature(shape=patch_dimensions_flat, dtype=tf.float32) ]\n",
    "image_features_dict = dict(zip(BANDS, image_columns))\n",
    "# Note that you can make one dataset from many files by specifying a list.\n",
    "image_dataset = tf.data.TFRecordDataset(image_files_list, compression_type='GZIP')\n",
    "\n",
    "\n",
    "# Parsing function.\n",
    "def parse_image(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_features_dict)\n",
    "\n",
    "# Parse the data into tensors, one long tensor per patch.\n",
    "image_dataset = image_dataset.map(parse_image, num_parallel_calls=5)\n",
    "\n",
    "\n",
    "image_dataset = image_dataset.map(lambda features: tf.transpose(list(features.values())), num_parallel_calls=5)\n",
    "\n",
    "\n",
    "# Break our long tensors into many little ones.\n",
    "image_dataset = image_dataset.flat_map(\n",
    "  lambda features: tf.data.Dataset.from_tensor_slices(features)\n",
    ")\n",
    "\n",
    "# Turn each patch into a batch.\n",
    "image_dataset = image_dataset.batch(patch_width * patch_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513/513 [==============================] - 40s 77ms/step\n",
      "[0.92006546]\n",
      "(33619968, 1)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# Run prediction in batches, with as many steps as there are patches.\n",
    "predictions = model.predict(image_dataset, steps=patches, verbose=1)\n",
    "\n",
    "# Note that the predictions come as a numpy array.  Check the first one.\n",
    "print(predictions[0])\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions in TIFF tiles 1 tile per batch\n",
    "def save_as_tiff(predictions, mixer, out_dir):\n",
    "    from osgeo import gdal, osr\n",
    "    base_trans=mixer['projection']['affine']['doubleMatrix']\n",
    "    epsg=int(mixer['projection']['crs'].split(':')[1])\n",
    "    spref=osr.SpatialReference()\n",
    "    spref.ImportFromEPSG(epsg)\n",
    "    proj=tt.ExportToWkt()  \n",
    "    \n",
    "    patch_width = mixer['patchDimensions'][0]\n",
    "    patch_height = mixer['patchDimensions'][1]\n",
    "    patch_lens=patch_width*patch_height\n",
    "    patches = mixer['totalPatches'] \n",
    "    cols=mixer['patchesPerRow']\n",
    "    rows=int(patches/cols)\n",
    "\n",
    "    for i in range(patches):\n",
    "        row=i//cols\n",
    "        col=i%cols\n",
    "        dx=patch_width*col\n",
    "        dy=patch_width*row\n",
    "        trans=base_trans.copy()\n",
    "        trans[0]=base_trans[2]+base_trans[0]*dx\n",
    "        trans[1]=base_trans[0]\n",
    "        trans[2]=0\n",
    "        trans[3]=base_trans[-1]+base_trans[-2]*dy\n",
    "        trans[4]=0\n",
    "        trans[5]=base_trans[-2]\n",
    "        curar=predictions[i*patch_lens:(i+1)*patch_lens].reshape(mixer['patchDimensions'])\n",
    "        trans=tuple(trans)        \n",
    "        \n",
    "        to_path='%s/im_%04d.tif' % (out_dir,i)               \n",
    "        \n",
    "        driver = gdal.GetDriverByName('GTiff')\n",
    "        dataset = driver.Create(to_path, patch_width,\n",
    "                patch_height,\n",
    "                1,\n",
    "                gdal.GDT_Float32)\n",
    "#                                 , options=['COMPRESS=LZW'])\n",
    "        dataset.SetProjection(proj)\n",
    "        dataset.SetGeoTransform(trans)\n",
    "        \n",
    "        outband = dataset.GetRasterBand(1)\n",
    "        outband.WriteArray(curar)\n",
    "        dataset.FlushCache()\n",
    "        del dataset\n",
    "        del outband\n",
    "        del curar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir='data/out'\n",
    "save_as_tiff(predictions, mixer, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with patch 1 of 12...\n",
      "Done with patch 2 of 12...\n",
      "Done with patch 3 of 12...\n",
      "Done with patch 4 of 12...\n"
     ]
    }
   ],
   "source": [
    "# NOT NESSESARY Write to tfrecord\n",
    "\n",
    "OUTPUT_IMAGE_FILE='data/outt.TFRecord'\n",
    "writer = tf.io.TFRecordWriter(OUTPUT_IMAGE_FILE)\n",
    "\n",
    "# Every patch-worth of predictions we'll dump an example into the output\n",
    "# file with a single feature that holds our predictions. Since our predictions\n",
    "# are already in the order of the exported data, the patches we create here\n",
    "# will also be in the right order.\n",
    "patch = []\n",
    "cur_patch = 1\n",
    "for prediction in predictions:\n",
    "    patch.append(prediction)\n",
    "  \n",
    "  # Once we've seen a patches-worth of class_ids...\n",
    "    if (len(patch) == patch_width * patch_height):\n",
    "        print('Done with patch ' + str(cur_patch) + ' of ' + str(patches) + '...')\n",
    "        # Create an example\n",
    "        example = tf.train.Example(\n",
    "          features=tf.train.Features(\n",
    "            feature={\n",
    "              'prediction': tf.train.Feature(\n",
    "                  float_list=tf.train.FloatList(\n",
    "                      value=patch))\n",
    "            }\n",
    "          )\n",
    "        )\n",
    "        # Write the example to the file and clear our patch array so it's ready for\n",
    "        # another batch of class ids\n",
    "        writer.write(example.SerializeToString())\n",
    "        patch = []\n",
    "        cur_patch += 1\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
